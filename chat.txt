#!/usr/bin/env bash
set -euo pipefail

-----------------------------------------------------------------------------
MASTER ORCHESTRATOR MENU
-----------------------------------------------------------------------------
PROJECT_NAME=""
GITHUB_REPO=""
AZURE_LOCATION="eastus"
DEPLOY_MARKETING=false

Check prerequisites
check_prereqs() {
echo "=== Checking Prerequisites ==="

text
# Check Azure CLI
if ! command -v az &> /dev/null; then
    echo "âŒ Azure CLI not found. Install: https://aka.ms/installazurecli"
    exit 1
else
    echo "âœ… Azure CLI found"
fi

# Check Git
if ! command -v git &> /dev/null; then
    echo "âŒ Git not found. Install git first."
    exit 1
else
    echo "âœ… Git found"
fi

# Check GitHub CLI (optional but recommended)
if command -v gh &> /dev/null; then
    echo "âœ… GitHub CLI found"
    HAS_GH_CLI=true
else
    echo "âš ï¸  GitHub CLI not found (install for auto repo creation: https://cli.github.com/)"
    HAS_GH_CLI=false
fi

# Check Azure login
if ! az account show &> /dev/null; then
    echo "âš ï¸  Not logged into Azure. Running 'az login'..."
    az login
else
    echo "âœ… Azure logged in"
fi

echo ""
}

Interactive project configuration
configure_project() {
echo "=== Project Configuration ==="

text
# Project name
while [[ -z "$PROJECT_NAME" ]]; do
    read -p "Enter project name (lowercase, hyphens only): " PROJECT_NAME
    if ! [[ $PROJECT_NAME =~ ^[a-z0-9-]+$ ]]; then
        echo "âŒ Invalid name. Use lowercase letters, numbers, and hyphens only."
        PROJECT_NAME=""
    fi
done

# GitHub repo
while [[ -z "$GITHUB_REPO" ]]; do
    read -p "Enter GitHub repo name (e.g., my-ai-platform): " GITHUB_REPO
done

# Azure location
read -p "Azure region [eastus]: " AZURE_LOCATION_INPUT
AZURE_LOCATION=${AZURE_LOCATION_INPUT:-eastus}

# Marketing deployment
read -p "Deploy marketing automation? (y/n) [n]: " DEPLOY_MARKETING_INPUT
if [[ $DEPLOY_MARKETING_INPUT =~ ^[Yy]$ ]]; then
    DEPLOY_MARKETING=true
fi

echo ""
echo "ðŸ“‹ Configuration Summary:"
echo "   Project: $PROJECT_NAME"
echo "   GitHub Repo: $GITHUB_REPO"
echo "   Azure Region: $AZURE_LOCATION"
echo "   Marketing: $DEPLOY_MARKETING"
echo ""

read -p "Continue? (y/n): " confirm
if [[ ! $confirm =~ ^[Yy]$ ]]; then
    echo "Exiting..."
    exit 0
fi
}

Create project directory structure
create_project_structure() {
echo "=== Creating Project Structure ==="

text
if [[ -d "$PROJECT_NAME" ]]; then
    read -p "Directory '$PROJECT_NAME' exists. Overwrite? (y/n): " overwrite
    if [[ ! $overwrite =~ ^[Yy]$ ]]; then
        echo "Exiting..."
        exit 1
    fi
    rm -rf "$PROJECT_NAME"
fi

mkdir -p "$PROJECT_NAME"/{src,scripts,.github/workflows,docs}
cd "$PROJECT_NAME"

echo "âœ… Created directory structure:"
tree -a . 2>/dev/null || find . -type d | sort
echo ""
}

Generate project.md
generate_project_md() {
echo "=== Generating project.md ==="

text
cat <<EOF > project.md
Azure AI Inference Arbitrage Platform
Revenue Model
Resell GPU-based AI inference at 200-300% margin by arbitraging Azure spot instances and serverless architecture.

Architecture
API Layer: Azure API Management (consumption tier) - $0 idle cost
Compute: VM Scale Sets with Spot priority (80% discount)
Models: Quantized Llama-3-70B, Mixtral 8x7B, Phi-3-mini
Caching: Azure Cosmos DB (serverless) - pay-per-request
Orchestration: Azure Functions (consumption)
Monitoring: Log Analytics + Application Insights
Economics
Azure Cost: ~$0.15/hour per GPU spot instance
Revenue: $0.002/1K tokens (2x cheaper than OpenAI)
Margin: 60-70% per token
Scale: $1k credits = ~6,600 GPU-hours = 2B tokens = $4k revenue
Break-even: 72 hours
ROI: 400% in 14 days
Features
Intelligent Model Routing (auto-select cheapest model)
Smart Caching (40% hit rate)
Spot Preemption Resilience (<30s failover)
Usage-Based Metering
Global Load Balancing
Deployment
```bash
./deploy.sh
```
EOF
echo "âœ… Generated project.md"
}

Generate deploy.sh
generate_deploy_sh() {
echo "=== Generating deploy.sh ==="

text
cat <<'EOF' > deploy.sh
#!/usr/bin/env bash
set -euo pipefail

-----------------------------------------------------------------------------
CONFIGURATION
-----------------------------------------------------------------------------
PROJECT_NAME="
P
R
O
J
E
C
T
N
A
M
E
:
âˆ’
a
i
âˆ’
a
r
b
i
t
r
a
g
e
"
L
O
C
A
T
I
O
N
=
"
PROJECT 
N
â€‹
 AME:âˆ’aiâˆ’arbitrage"LOCATION="{LOCATION:-eastus}"
RESOURCE_GROUP="
P
R
O
J
E
C
T
N
A
M
E
âˆ’
r
g
"
T
A
G
S
=
"
p
r
o
j
e
c
t
=
PROJECT 
N
â€‹
 AMEâˆ’rg"TAGS="project={PROJECT_NAME} cost-category=arbitrage auto-deploy=true"

APIM_SKU="Consumption"
FUNCTION_SKU="Y1"
COSMOS_DB_SKU="Serverless"
VMSS_SKU="Standard_NC4as_T4_v3"
SPOT_MAX_PRICE="0.15"

-----------------------------------------------------------------------------
UTILITY FUNCTIONS
-----------------------------------------------------------------------------
log() { echo -e "\033[1;32m[
(
d
a
t
e
+
(date+\033[0m"; }
warn() { echo -e "\033[1;33m[WARNING] *\033[0m" >&2; } error() { echo -e "\033[1;31m[ERROR] \033[0m" >&2; exit 1; }

check_az_cli() {
if ! command -v az &> /dev/null; then
error "Azure CLI not found. Install from: https://aka.ms/installazurecli"
fi
}

ensure_logged_in() {
if ! az account show &> /dev/null; then
log "Not logged in. Running 'az login'..."
az login
fi
}

get_subscription_id() {
az account show --query id -o tsv
}

Idempotent resource creation
create_resource_group() {
log "Checking resource group: 
R
E
S
O
U
R
C
E
G
R
O
U
P
"
i
f
a
z
g
r
o
u
p
s
h
o
w
âˆ’
âˆ’
n
a
m
e
"
RESOURCE 
G
â€‹
 ROUP"ifazgroupshowâˆ’âˆ’name"{RESOURCE_GROUP}" &> /dev/null; then
warn "Resource group already exists"
else
log "Creating resource group in 
L
O
C
A
T
I
O
N
.
.
.
"
a
z
g
r
o
u
p
c
r
e
a
t
e
 
âˆ’
âˆ’
n
a
m
e
"
LOCATION..."azgroupcreate âˆ’âˆ’name"{RESOURCE_GROUP}"
--location "
L
O
C
A
T
I
O
N
"
 
âˆ’
âˆ’
t
a
g
s
LOCATION" âˆ’âˆ’tags{TAGS}
fi
}

create_aad_identity() {
log "Configuring Azure AD managed identity..."

text
local app_id
if app_id=$(az ad app list --display-name "${PROJECT_NAME}-identity" --query '[0].appId' -o tsv) && [ -n "$app_id" ]; then
    warn "AAD app already exists"
else
    app_id=$(az ad app create --display-name "${PROJECT_NAME}-identity" --query appId -o tsv)
    sleep 10
fi

local sp_id
if sp_id=$(az ad sp list --app-id "${app_id}" --query '[0].id' -o tsv) && [ -n "$sp_id" ]; then
    warn "Service principal already exists"
else
    sp_id=$(az ad sp create --app-id "${app_id}" --query id -o tsv)
    sleep 10
fi

echo "AAD_APP_ID=${app_id}" > .env
echo "AAD_SP_ID=${sp_id}" >> .env
log "Identity configured: ${app_id}"
}

create_cosmos_db() {
log "Setting up Cosmos DB (serverless)..."
local account_name="
P
R
O
J
E
C
T
N
A
M
E
c
a
c
h
e
PROJECT 
N
â€‹
 AMEcache(date +%s | tail -c 6)"

text
if az cosmosdb show --name "${account_name}" --resource-group "${RESOURCE_GROUP}" &> /dev/null; then
    warn "CosmosDB account already exists"
else
    az cosmosdb create \
        --name "${account_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --locations regionName="${LOCATION}" failoverPriority=0 \
        --capabilities EnableServerless \
        --default-consistency-level Eventual \
        --tags ${TAGS}
    
    az cosmosdb sql database create \
        --account-name "${account_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --name "inferencecache"
    
    az cosmosdb sql container create \
        --account-name "${account_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --database-name "inferencecache" \
        --name "responses" \
        --partition-key-path "/modelId" \
        --ttl 3600
fi

echo "COSMOS_ACCOUNT=${account_name}" >> .env
}

create_storage_account() {
log "Creating storage account..."
local storage_name="
P
R
O
J
E
C
T
N
A
M
E
d
i
a
g
PROJECT 
N
â€‹
 AMEdiag(date +%s | tail -c 6)"

text
if az storage account show --name "${storage_name}" --resource-group "${RESOURCE_GROUP}" &> /dev/null; then
    warn "Storage account already exists"
else
    az storage account create \
        --name "${storage_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --location "${LOCATION}" \
        --sku Standard_LRS \
        --kind StorageV2 \
        --tags ${TAGS}
fi

echo "STORAGE_ACCOUNT=${storage_name}" >> .env
}

create_vnet_and_nsg() {
log "Setting up network infrastructure..."
local vnet_name="
P
R
O
J
E
C
T
N
A
M
E
âˆ’
v
n
e
t
"
l
o
c
a
l
s
u
b
n
e
t
n
a
m
e
=
"
PROJECT 
N
â€‹
 AMEâˆ’vnet"localsubnet 
n
â€‹
 ame="{PROJECT_NAME}-subnet"
local nsg_name="${PROJECT_NAME}-nsg"

text
if az network nsg show --name "${nsg_name}" --resource-group "${RESOURCE_GROUP}" &> /dev/null; then
    warn "NSG already exists"
else
    az network nsg create \
        --name "${nsg_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --tags ${TAGS}
    
    az network nsg rule create \
        --nsg-name "${nsg_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --name "Allow-APIM" \
        --priority 100 \
        --destination-port-ranges 443 \
        --protocol Tcp \
        --source-address-prefixes "AzureLoadBalancer" \
        --access Allow
    
    az network nsg rule create \
        --nsg-name "${nsg_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --name "Deny-All" \
        --priority 4096 \
        --protocol * \
        --source-address-prefixes "*" \
        --destination-port-ranges "*" \
        --access Deny
fi

if az network vnet show --name "${vnet_name}" --resource-group "${RESOURCE_GROUP}" &> /dev/null; then
    warn "VNet already exists"
else
    az network vnet create \
        --name "${vnet_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --location "${LOCATION}" \
        --address-prefix 10.0.0.0/16 \
        --subnet-name "${subnet_name}" \
        --subnet-prefix 10.0.1.0/24 \
        --network-security-group "${nsg_name}" \
        --tags ${TAGS}
fi

echo "VNET_NAME=${vnet_name}" >> .env
echo "SUBNET_NAME=${subnet_name}" >> .env
}

create_vmss() {
log "Deploying spot instance GPU VMSS..."
local vmss_name="${PROJECT_NAME}-gpu-pool"

text
if az vmss show --name "${vmss_name}" --resource-group "${RESOURCE_GROUP}" &> /dev/null; then
    warn "VMSS already exists"
else
    local image_urn=$(az vm image list --publisher Canonical --offer 0001-com-ubuntu-server-jammy --sku 22_04-lts-gen2 --all --query '[0].urn' -o tsv)
    
    az vmss create \
        --name "${vmss_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --location "${LOCATION}" \
        --vm-sku "${VMSS_SKU}" \
        --image "${image_urn}" \
        --vnet-name "${vnet_name}" \
        --subnet "${subnet_name}" \
        --nsg "${nsg_name}" \
        --lb "" \
        --instance-count 0 \
        --priority Spot \
        --max-price "${SPOT_MAX_PRICE}" \
        --eviction-policy Deallocate \
        --storage-sku Standard_LRS \
        --ephemeral-os-disk true \
        --os-disk-caching ReadOnly \
        --admin-username azureuser \
        --generate-ssh-keys \
        --assign-identity '[system]' \
        --scope "/subscriptions/$(get_subscription_id)/resourceGroups/${RESOURCE_GROUP}" \
        --custom-data "$(base64 -w0 <<'EOF'
#!/bin/bash
apt-get update
apt-get install -y docker.io nvidia-container-toolkit
systemctl enable --now docker
nvidia-ctk runtime configure --runtime=docker
systemctl restart docker
docker pull ghcr.io/ggerganov/llama.cpp:server-cuda
docker pull ghcr.io/mistralai/mistral-src:latest
EOF
)"
--tags ${TAGS}
--upgrade-policy-mode Automatic

text
    az vmss update \
        --name "${vmss_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --set virtualMachineProfile.diagnosticsProfile="{\"bootDiagnostics\":{\"enabled\":true,\"storageUri\":\"https://${storage_name}.blob.core.windows.net/\"}}"
fi

echo "VMSS_NAME=${vmss_name}" >> .env
}

create_function_app() {
log "Creating serverless function app..."
local func_name="
P
R
O
J
E
C
T
N
A
M
E
âˆ’
o
r
c
h
e
s
t
r
a
t
o
r
"
l
o
c
a
l
s
t
o
r
a
g
e
n
a
m
e
=
"
PROJECT 
N
â€‹
 AMEâˆ’orchestrator"localstorage 
n
â€‹
 ame="{PROJECT_NAME}func$(date +%s | tail -c 6)"

text
if ! az storage account show --name "${storage_name}" --resource-group "${RESOURCE_GROUP}" &> /dev/null; then
    az storage account create \
        --name "${storage_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --location "${LOCATION}" \
        --sku Standard_LRS \
        --kind StorageV2 \
        --tags ${TAGS}
fi

if az functionapp show --name "${func_name}" --resource-group "${RESOURCE_GROUP}" &> /dev/null; then
    warn "Function app already exists"
else
    az functionapp create \
        --name "${func_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --storage-account "${storage_name}" \
        --consumption-plan-location "${LOCATION}" \
        --runtime python \
        --runtime-version 3.11 \
        --functions-version 4 \
        --os-type Linux \
        --assign-identity '[system]' \
        --tags ${TAGS}
    
    local func_identity=$(az functionapp identity show --name "${func_name}" --resource-group "${RESOURCE_GROUP}" --query principalId -o tsv)
    az role assignment create \
        --role "Virtual Machine Contributor" \
        --assignee "${func_identity}" \
        --scope "/subscriptions/$(get_subscription_id)/resourceGroups/${RESOURCE_GROUP}"
fi

echo "FUNCTION_NAME=${func_name}" >> .env
}

create_api_management() {
log "Setting up API Management..."
local apim_name="${PROJECT_NAME}-gateway"

text
if az apim show --name "${apim_name}" --resource-group "${RESOURCE_GROUP}" &> /dev/null; then
    warn "API Management already exists"
else
    az apim create \
        --name "${apim_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --location "${LOCATION}" \
        --publisher-email "admin@${PROJECT_NAME}.com" \
        --publisher-name "${PROJECT_NAME}" \
        --sku-name "${APIM_SKU}" \
        --tags ${TAGS}
    
    az apim api import \
        --service-name "${apim_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --api-id "inference-v1" \
        --specification-format OpenApi \
        --specification-path "$(pwd)/openapi.json" \
        --path "/v1" \
        --api-type http
fi

echo "APIM_NAME=${apim_name}" >> .env
}

deploy_autoscaling_rules() {
log "Configuring autonomous scaling..."

text
az monitor autoscale create \
    --resource-group "${RESOURCE_GROUP}" \
    --resource "${vmss_name}" \
    --resource-type Microsoft.Compute/virtualMachineScaleSets \
    --name "${vmss_name}-autoscale" \
    --min-count 0 \
    --max-count 20 \
    --count 0

az monitor autoscale rule create \
    --autoscale-name "${vmss_name}-autoscale" \
    --resource-group "${RESOURCE_GROUP}" \
    --condition "Percentage CPU > 70 avg 5m" \
    --scale out 2

az monitor autoscale rule create \
    --autoscale-name "${vmss_name}-autoscale" \
    --resource-group "${RESOURCE_GROUP}" \
    --condition "Percentage CPU < 20 avg 10m" \
    --scale in 1
}

-----------------------------------------------------------------------------
MAIN DEPLOYMENT
-----------------------------------------------------------------------------
main() {
log "=== Azure AI Inference Arbitrage Platform Deployment ==="

text
check_az_cli
ensure_logged_in
log "Subscription: $(get_subscription_id)"

create_resource_group
create_aad_identity
create_storage_account
create_cosmos_db
create_vnet_and_nsg
create_vmss
create_function_app
create_api_management
deploy_autoscaling_rules

log "=== Deployment Complete ==="
log "Environment: .env"
log "Next: ./deploy-marketing.sh (if enabled)"
}

if [[ "
B
A
S
H
S
O
U
R
C
E
[
0
]
"
=
=
"
BASH 
S
â€‹
 OURCE[0]"=="{0}" ]]; then
main "$@"
fi
EOF
echo "âœ… Generated deploy.sh"
}

Generate deploy-marketing.sh
generate_deploy_marketing_sh() {
if [[ "$DEPLOY_MARKETING" != true ]]; then
echo "âš ï¸ Marketing automation disabled. Skipping deploy-marketing.sh"
return
fi

text
echo "=== Generating deploy-marketing.sh ==="

cat <<'EOF' > deploy-marketing.sh
#!/usr/bin/env bash
set -euo pipefail

PROJECT_NAME="
P
R
O
J
E
C
T
N
A
M
E
:
âˆ’
a
i
âˆ’
a
r
b
i
t
r
a
g
e
"
R
E
S
O
U
R
C
E
G
R
O
U
P
=
"
PROJECT 
N
â€‹
 AME:âˆ’aiâˆ’arbitrage"RESOURCE 
G
â€‹
 ROUP="{PROJECT_NAME}-marketing-rg"
LOCATION="${LOCATION:-eastus}"

log() { echo -e "\033[1;34m[MARKETING] *\033[0m"; } warn() { echo -e "\033[1;33m[WARNING] *\033[0m" >&2; }

load_env() {
if [[ -f .env ]]; then
source .env
fi
}

deploy_github_prospector() {
log "Deploying GitHub Prospector bot..."

text
read -p "Enter GitHub Personal Access Token: " GITHUB_TOKEN
read -p "Enter Crunchbase API Key: " CRUNCHBASE_API_KEY
read -p "Enter Hunter.io API Key: " HUNTER_API_KEY

# Create container instance
az container create \
    --name "${PROJECT_NAME}-gh-prospector" \
    --resource-group "${RESOURCE_GROUP}" \
    --image "python:3.11-slim" \
    --command-line "bash -c 'pip install requests pandas && python /app/prospector.py'" \
    --environment-variables \
        GITHUB_TOKEN="${GITHUB_TOKEN}" \
        CRUNCHBASE_API_KEY="${CRUNCHBASE_API_KEY}" \
        HUNTER_API_KEY="${HUNTER_API_KEY}" \
    --restart-policy OnFailure \
    --cpu 1 --memory 2 \
    --location "${LOCATION}" \
    --tags project="${PROJECT_NAME}" automation="github-prospector"

# Generate prospector script
cat <<'PYEOF' > scripts/prospector.py
import os, requests, csv
from datetime import datetime, timedelta

def get_github_leads():
headers = {'Authorization': f'token {os.environ["GITHUB_TOKEN"]}'}
query = "openai language:python pushed:>2024-01-01"
url = f"https://api.github.com/search/repositories?q={query}"

text
repos = requests.get(url, headers=headers).json()['items'][:1000]
leads = []

for repo in repos:
    # Get contributors
    contrib_url = repo['contributors_url']
    contributors = requests.get(contrib_url, headers=headers).json()[:3]
    
    for dev in contributors:
        # Enrich email
        email = requests.get(
            f"https://api.hunter.io/v2/email-finder",
            params={"domain": "github.com", "first_name": dev['login']},
            headers={"api_key": os.environ["HUNTER_API_KEY"]}
        ).json().get('data', {}).get('email', '')
        
        if email:
            leads.append({
                "name": dev['login'],
                "email": email,
                "repo": repo['name'],
                "stars": repo['stargazers_count'],
                "last_active": repo['updated_at']
            })

# Save leads
with open('/output/leads.csv', 'w') as f:
    csv.DictWriter(f, fieldnames=leads[0].keys()).writerows(leads)

print(f"âœ… Generated {len(leads)} leads")
if name == "main":
get_github_leads()
PYEOF

text
log "GitHub Prospector deployed"
}

deploy_cost_calculator() {
log "Deploying cost calculator..."

text
# Create static web app
az staticwebapp create \
    --name "${PROJECT_NAME}-calculator" \
    --resource-group "${RESOURCE_GROUP}" \
    --location "${LOCATION}" \
    --sku Free \
    --tags project="${PROJECT_NAME}" lead-gen="calculator"

# Generate calculator
cat <<'HTMLOF' > calculator.html
<!DOCTYPE html> <html> <head> <title>AI API Cost Calculator - Save 50%</title> <style> body { font-family: Arial; max-width: 800px; margin: 0 auto; padding: 40px; } input[type="file"] { margin: 20px 0; } #savings { font-size: 2em; color: #00aa00; margin: 30px 0; } .cta-button { background: #00aa00; color: white; padding: 15px 30px; text-decoration: none; border-radius: 5px; } </style> </head> <body> <h1>Cut Your AI API Costs by 50%</h1> <p>Upload your OpenAI usage JSON to see instant savings:</p> <input type="file" id="bill" accept=".json"> <div id="savings"></div> <script> document.getElementById('bill').onchange = function(e) { const reader = new FileReader(); reader.onload = function() { const data = JSON.parse(reader.result); const monthly_cost = data.total_usage || 0; const savings = monthly_cost * 0.5; document.getElementById('savings').innerHTML = `<h2>You'd save $${savings.toFixed(2)}/month</h2> <a href="https://${APIM_NAME}.azure-api.net/signup" class="cta-button">Get Free API Key</a>`; }; reader.readAsText(e.target.files[0]); } </script> </body> </html> HTMLOF
text
log "Cost calculator deployed"
}

setup_sendgrid() {
log "Setting up SendGrid email automation..."

text
read -p "Enter SendGrid API Key: " SENDGRID_API_KEY

# Create email templates
curl -X POST "https://api.sendgrid.com/v3/marketing/singlesends" \
    -H "Authorization: Bearer ${SENDGRID_API_KEY}" \
    -H "Content-Type: application/json" \
    -d @- <<'JSONEOF'
{
"name": "AI API Value Prop",
"email_config": {
"subject": "Cut your AI API costs by 50% (same quality)",
"html_content": "<p>Hi {{first_name}},</p><p>I saw you're using OpenAI. Our API is 2x cheaper with identical performance.</p><p>1M free tokens: <a href='{{signup_url}}'>Get Started</a></p>",
"plain_content": "Hi {{first_name}}, Cut AI costs 50%: {{signup_url}}"
}
}
JSONEOF

text
log "SendGrid sequences configured"
}

setup_reddit() {
log "Setting up Reddit automation..."

text
read -p "Enter Reddit Client ID: " REDDIT_CLIENT_ID
read -p "Enter Reddit Client Secret: " REDDIT_SECRET

# Create GitHub Action for Reddit bot
cat <<'YAMLOF' > .github/workflows/reddit-strike.yml
name: Reddit Precision Strike
on:
schedule:
- cron: '0 */6 * * *' # Every 6 hours
jobs:
strike:
runs-on: ubuntu-latest
steps:
- uses: actions/checkout@v4
- uses: actions/setup-python@v4
with: {python-version: '3.11'}
- run: pip install praw
- run: python scripts/reddit_bot.py
env:
REDDIT_CLIENT_ID: 
s
e
c
r
e
t
s
.
R
E
D
D
I
T
C
L
I
E
N
T
I
D
R
E
D
D
I
T
S
E
C
R
E
T
:
secrets.REDDIT 
C
â€‹
 LIENT 
I
â€‹
 DREDDIT 
S
â€‹
 ECRET:{{ secrets.REDDIT_SECRET }}
APIM_NAME: ${{ secrets.APIM_NAME }}
YAMLOF

text
cat <<'PYEOF' > scripts/reddit_bot.py
import praw, os, time

reddit = praw.Reddit(
client_id=os.environ['REDDIT_CLIENT_ID'],
client_secret=os.environ['REDDIT_SECRET'],
user_agent="AI Cost Bot 1.0"
)

for submission in reddit.subreddit("MachineLearning+OpenAI+LocalLLaMA").hot(limit=50):
if any(kw in submission.title.lower() for kw in ["api cost", "expensive", "rate limit"]):
comment = f"""
ðŸ”¥ We built an API that's 50% cheaper than OpenAI with Mixtral-8x7B
Benchmark: 1M tokens = 
2
v
s
2vs4 at OpenAI
Free tier (no CC): https://{os.environ['APIM_NAME']}.azure-api.net/signup
"""
submission.reply(comment)
time.sleep(600) # Rate limit
PYEOF

text
log "Reddit automation configured"
}

Main marketing deployment
main() {
log "=== Deploying Marketing Automation ==="

text
load_env

# Create marketing resource group
if ! az group show --name "${RESOURCE_GROUP}" &> /dev/null; then
    az group create --name "${RESOURCE_GROUP}" --location "${LOCATION}" --tags project="${PROJECT_NAME}" component="marketing"
fi

deploy_github_prospector
deploy_cost_calculator
setup_sendgrid
setup_reddit

log "=== Marketing Engine Ready ==="
log "Monitor leads via Azure Container Instances and GitHub Actions"
}

if [[ "
B
A
S
H
S
O
U
R
C
E
[
0
]
"
=
=
"
BASH 
S
â€‹
 OURCE[0]"=="{0}" ]]; then
main "$@"
fi
EOF
echo "âœ… Generated deploy-marketing.sh"
}

Generate OpenAPI spec
generate_openapi_spec() {
echo "=== Generating openapi.json ==="

text
cat <<'EOF' > openapi.json
{
"openapi": "3.0.0",
"info": {
"title": "AI Inference API",
"version": "1.0.0"
},
"paths": {
"/chat/completions": {
"post": {
"summary": "Chat completions",
"requestBody": {
"content": {
"application/json": {
"schema": {
"type": "object",
"properties": {
"model": {"type": "string"},
"messages": {"type": "array"}
}
}
}
}
},
"responses": {
"200": {
"description": "Success",
"content": {
"application/json": {
"schema": {
"type": "object",
"properties": {
"choices": {"type": "array"}
}
}
}
}
}
}
}
}
}
}
EOF
echo "âœ… Generated openapi.json"
}

Generate function app source code
generate_function_source() {
echo "=== Generating function app source ==="

text
mkdir -p src/api_orchestrator

cat <<'EOF' > src/api_orchestrator/__init__.py
import azure.functions as func
import os, json, requests
from azure.identity import DefaultAzureCredential
from azure.mgmt.compute import ComputeManagementClient

app = func.FunctionApp()

@app.function_name(name="inference_orchestrator")
@app.route(route="chat/completions", methods=["POST"], auth_level=func.AuthLevel.FUNCTION)
def main(req: func.HttpRequest) -> func.HttpResponse:
"""Routes inference requests to cheapest available model"""

text
# Parse request
body = req.get_json()
model = body.get("model", "mixtral-8x7b")

# Get VMSS instances
credential = DefaultAzureCredential()
compute_client = ComputeManagementClient(credential, os.environ["AZURE_SUBSCRIPTION_ID"])

# Route logic (simplified)
if model == "llama-3-70b":
    endpoint = f"http://{os.environ['VMSS_NAME']}.internal:8080/v1/chat/completions"
else:
    endpoint = f"http://{os.environ['VMSS_NAME']}.internal:8080/v1/chat/completions"

# Forward request
response = requests.post(endpoint, json=body, headers={"Authorization": f"Bearer {os.environ['API_KEY']}"})

return func.HttpResponse(
    body=response.text,
    status_code=response.status_code,
    headers={"Content-Type": "application/json"}
)
EOF

text
cat <<'EOF' > src/requirements.txt
azure-functions
azure-identity
azure-mgmt-compute
requests
EOF

text
echo "âœ… Generated function app source"
}

Generate documentation
generate_docs() {
echo "=== Generating documentation ==="

text
cat <<'EOF' > docs/deployment-guide.md
Deployment Guide
Quick Start
Run ./master-deploy.sh
Follow interactive prompts
Deploy infrastructure: cd <project> && ./deploy.sh
Deploy marketing: ./deploy-marketing.sh
Configuration
Set these environment variables:

GITHUB_TOKEN: For lead generation
SENDGRID_API_KEY: For email automation
TWITTER_BEARER_TOKEN: For social monitoring
CRUNCHBASE_API_KEY: For company enrichment
Monitoring
Azure Portal: Resource groups â†’ <project>-rg

Costs: Cost Management + Billing

Logs: Log Analytics workspace
EOF

cat <<'EOF' > docs/api-usage.md

API Usage
Authentication
bash
curl -X POST https://<apim-name>.azure-api.net/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model": "mixtral-8x7b", "messages": [{"role": "user", "content": "Hello"}]}' //make this better

Thought Process
expand
Improved API Usage Documentation
Here's a significantly enhanced version of the docs/api-usage.md file:

bash
# Generate documentation
generate_docs() {
    echo "=== Generating documentation ==="
    
    cat <<'EOF' > docs/deployment-guide.md
# Deployment Guide

## Quick Start
1. Run `./master-deploy.sh`
2. Follow interactive prompts
3. Deploy infrastructure: `cd <project> && ./deploy.sh`
4. Deploy marketing: `./deploy-marketing.sh`

## Configuration
Set these environment variables:
- `GITHUB_TOKEN`: For lead generation
- `SENDGRID_API_KEY`: For email automation
- `TWITTER_BEARER_TOKEN`: For social monitoring
- `CRUNCHBASE_API_KEY`: For company enrichment

## Monitoring
- Azure Portal: Resource groups â†’ <project>-rg
- Costs: Cost Management + Billing
- Logs: Log Analytics workspace
EOF
    
    cat <<'EOF' > docs/api-usage.md
# API Usage Guide

## Base URL
https://.azure-api.net/v1

text

---

## Authentication

All requests require an API key passed via the `Authorization` header:

```bash
Authorization: Bearer YOUR_API_KEY
Get your API key from the Developer Portal.

Endpoints
POST /chat/completions
Generate chat completions using our optimized model routing.

Request
bash
curl -X POST "https://<apim-name>.azure-api.net/v1/chat/completions" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mixtral-8x7b",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Explain quantum computing in simple terms."}
    ],
    "max_tokens": 512,
    "temperature": 0.7,
    "stream": false
  }'
Parameters
Parameter	Type	Required	Default	Description
model	string	Yes	-	Model identifier (see Available Models)
messages	array	Yes	-	Conversation history
max_tokens	integer	No	256	Maximum tokens to generate
temperature	float	No	1.0	Sampling temperature (0.0-2.0)
top_p	float	No	1.0	Nucleus sampling parameter
stream	boolean	No	false	Enable streaming responses
stop	string/array	No	null	Stop sequences
Response
json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1699500000,
  "model": "mixtral-8x7b",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Quantum computing uses quantum bits (qubits)..."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 24,
    "completion_tokens": 156,
    "total_tokens": 180
  }
}
Available Models
Model	Context	Speed	Best For	Price (per 1M tokens)
mixtral-8x7b	32K	Fast	General tasks, coding	$2.00
llama-3-70b	8K	Medium	Complex reasoning	$3.00
phi-3-mini	4K	Fastest	Quick responses, low cost	$0.50
auto	Varies	Optimal	Cost-optimized routing	Variable
Using model: "auto" enables intelligent routing that selects the best model based on your prompt complexity and cost preferences.

Streaming Responses
For real-time token streaming:

bash
curl -X POST "https://<apim-name>.azure-api.net/v1/chat/completions" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -H "Accept: text/event-stream" \
  -d '{
    "model": "mixtral-8x7b",
    "messages": [{"role": "user", "content": "Write a poem about clouds"}],
    "stream": true
  }'
Streaming response format (SSE):

text
data: {"id":"chatcmpl-abc123","choices":[{"delta":{"content":"The"}}]}
data: {"id":"chatcmpl-abc123","choices":[{"delta":{"content":" clouds"}}]}
...
data: [DONE]
SDK Examples
Python
python
import openai

client = openai.OpenAI(
    base_url="https://<apim-name>.azure-api.net/v1",
    api_key="YOUR_API_KEY"
)

response = client.chat.completions.create(
    model="mixtral-8x7b",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ],
    max_tokens=256
)

print(response.choices[0].message.content)
Node.js / TypeScript
javascript
import OpenAI from 'openai';

const client = new OpenAI({
  baseURL: 'https://<apim-name>.azure-api.net/v1',
  apiKey: 'YOUR_API_KEY',
});

async function main() {
  const response = await client.chat.completions.create({
    model: 'mixtral-8x7b',
    messages: [
      { role: 'system', content: 'You are a helpful assistant.' },
      { role: 'user', content: 'Hello!' }
    ],
    max_tokens: 256,
  });
  
  console.log(response.choices[0].message.content);
}

main();
cURL with Streaming (Bash)
bash
#!/bin/bash

curl -sN "https://<apim-name>.azure-api.net/v1/chat/completions" \
  -H "Authorization: Bearer $API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mixtral-8x7b",
    "messages": [{"role": "user", "content": "Count to 10"}],
    "stream": true
  }' | while read -r line; do
    if [[ "$line" == data:* ]]; then
      echo "$line" | sed 's/^data: //' | jq -r '.choices[0].delta.content // empty' 2>/dev/null
    fi
  done
Error Handling
HTTP Status Codes
Code	Meaning	Action
200	Success	-
400	Bad Request	Check request format
401	Unauthorized	Verify API key
429	Rate Limited	Implement backoff
500	Server Error	Retry with backoff
503	Service Unavailable	Spot instance scaling, retry
Error Response Format
json
{
  "error": {
    "code": "rate_limit_exceeded",
    "message": "Rate limit exceeded. Please retry after 60 seconds.",
    "retry_after": 60
  }
}
Retry Logic (Python)
python
import time
import openai
from openai import RateLimitError, APIError

def call_with_retry(messages, max_retries=3):
    for attempt in range(max_retries):
        try:
            return client.chat.completions.create(
                model="mixtral-8x7b",
                messages=messages
            )
        except RateLimitError as e:
            wait = getattr(e, 'retry_after', 2 ** attempt)
            time.sleep(wait)
        except APIError as e:
            if e.status_code >= 500:
                time.sleep(2 ** attempt)
            else:
                raise
    raise Exception("Max retries exceeded")
Rate Limits
Tier	Requests/min	Tokens/min	Concurrent
Free	20	40,000	2
Starter	60	150,000	5
Pro	300	1,000,000	20
Enterprise	Unlimited	Unlimited	Custom
Rate limit headers included in responses:

text
X-RateLimit-Limit: 60
X-RateLimit-Remaining: 45
X-RateLimit-Reset: 1699500060
Pricing Comparison
Provider	GPT-4 Equivalent	Our Price	Savings
OpenAI GPT-4	$30/1M tokens	-	-
Our Llama-3-70B	-	$3/1M tokens	90%
OpenAI GPT-3.5	$2/1M tokens	-	-
Our Mixtral-8x7B	-	$2/1M tokens	Equal
Our Phi-3-mini	-	$0.50/1M tokens	75%
Best Practices
Use streaming for user-facing applications to reduce perceived latency
Set appropriate max_tokens to control costs and response length
Use model: "auto" for automatic cost optimization
Cache common queries - we handle this automatically (40% cache hit rate)
Implement retry logic for 5xx errors (spot instance preemption)
Support
Documentation: https://docs..com

Status Page: https://status..com

Email: support@.com

Discord: https://discord.gg/
EOF

cat <<'EOF' > docs/architecture.md

Architecture Overview
System Diagram
text
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚         Azure API Management        â”‚
                                    â”‚         (Consumption Tier)          â”‚
                                    â”‚         - Rate Limiting             â”‚
                                    â”‚         - Authentication            â”‚
                                    â”‚         - Request Routing           â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚                    â”‚                    â”‚
                              â–¼                    â–¼                    â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Azure Function â”‚  â”‚  Cosmos DB      â”‚  â”‚  Log Analytics  â”‚
                    â”‚  (Orchestrator) â”‚  â”‚  (Cache Layer)  â”‚  â”‚  (Monitoring)   â”‚
                    â”‚  - Model Router â”‚  â”‚  - Serverless   â”‚  â”‚  - Metrics      â”‚
                    â”‚  - Load Balance â”‚  â”‚  - 40% hit rate â”‚  â”‚  - Alerts       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚               VM Scale Set (Spot Instances)        â”‚
            â”‚               Standard_NC4as_T4_v3 (NVIDIA T4)     â”‚
            â”‚                                                    â”‚
            â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
            â”‚   â”‚ Instance â”‚  â”‚ Instance â”‚  â”‚ Instance â”‚  ...   â”‚
            â”‚   â”‚ Llama.cppâ”‚  â”‚ Llama.cppâ”‚  â”‚ Llama.cppâ”‚        â”‚
            â”‚   â”‚ + vLLM   â”‚  â”‚ + vLLM   â”‚  â”‚ + vLLM   â”‚        â”‚
            â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
            â”‚                                                    â”‚
            â”‚   Auto-scale: 0-20 instances based on demand      â”‚
            â”‚   Spot pricing: 80% discount (~$0.15/hr)          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Cost Breakdown
Component	SKU	Idle Cost	Active Cost
API Management	Consumption	$0	$3.50/million calls
Functions	Consumption	$0	$0.20/million executions
Cosmos DB	Serverless	$0	$0.25/million RUs
VMSS (Spot)	NC4as_T4_v3	$0	~$0.15/hour/instance
Storage	Standard LRS	~$2/month	~$2/month
Total Idle	-	~$2/month	-
Failover Strategy
Spot Preemption: 30-second warning â†’ drain requests â†’ scale to new instance

Region Failover: Secondary region warm standby (optional)

Model Fallback: If Llama-3-70B unavailable â†’ route to Mixtral-8x7B
EOF

echo "âœ… Generated documentation"
}

text

This enhanced documentation provides:

1. **Complete API reference** with all parameters documented
2. **Multiple SDK examples** (Python, Node.js, Bash)
3. **Streaming support** with proper SSE handling
4. **Comprehensive error handling** with retry logic examples
5. **Rate limit documentation** with tier breakdown
6. **Pricing comparison** showing value proposition
7. **Architecture documentation** with system diagrams
8. **Best practices** for production usage

Would you like me to also improve any other parts of the script, such as:
- Adding health check endpoints
- Implementing proper secrets management (Azure Key Vault)
- Adding Terraform/Bicep alternatives
- Creating a CI/CD pipeline for the function app?
Claude Opus 4.5
Adding health check endpoints

Implementing proper secrets management (Azure Key Vault)
Adding Terraform/Bicep alternatives
Creating a CI/CD pipeline for the function app? all approved. proceed with full implementation. output either a downloadable zip archive of project files, or pastable bashe heredoc to create relevant files for deploy

Thought Process
expand
bash
#!/usr/bin/env bash
set -euo pipefail

# =============================================================================
# AI INFERENCE ARBITRAGE PLATFORM - COMPLETE PROJECT GENERATOR
# =============================================================================
# This script creates a complete project structure with:
# - Health check endpoints
# - Azure Key Vault secrets management
# - Terraform infrastructure
# - Bicep infrastructure
# - CI/CD pipelines (GitHub Actions)
# - Function app source code
# - Documentation
# =============================================================================

PROJECT_NAME="${1:-ai-inference-platform}"

echo "ðŸš€ Creating project: ${PROJECT_NAME}"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# Create directory structure
mkdir -p "${PROJECT_NAME}"/{src/{api_orchestrator,health,shared},scripts,terraform,bicep,.github/workflows,docs,tests}

cd "${PROJECT_NAME}"

# =============================================================================
# 1. PROJECT ROOT FILES
# =============================================================================

cat > README.md << 'HEREDOC'
# AI Inference Arbitrage Platform

GPU-based AI inference reselling platform with 200-300% margins using Azure spot instances.

## Quick Start

```bash
# Option 1: Bash deployment
./deploy.sh

# Option 2: Terraform
cd terraform && terraform init && terraform apply

# Option 3: Bicep
az deployment sub create --location eastus --template-file bicep/main.bicep
Architecture
API Layer: Azure API Management (consumption tier)
Compute: VM Scale Sets with Spot priority (80% discount)
Models: Llama-3-70B, Mixtral 8x7B, Phi-3-mini
Caching: Azure Cosmos DB (serverless)
Orchestration: Azure Functions (consumption)
Secrets: Azure Key Vault
Features
âœ… Health check endpoints with liveness/readiness probes
âœ… Azure Key Vault secrets management
âœ… Terraform & Bicep IaC
âœ… GitHub Actions CI/CD
âœ… Auto-scaling 0-20 GPU instances
âœ… 40% cache hit rate
âœ… <30s spot preemption failover
Costs
State	Monthly Cost
Idle	~$5
Active (10 instances avg)	~$1,100
Revenue potential	~$4,000+
Documentation
Deployment Guide
API Usage
Architecture
Runbook
HEREDOC
cat > .gitignore << 'HEREDOC'

Environment
.env
.env.*
*.env

Terraform
terraform/.terraform/
terraform/.tfstate
terraform/.tfstate.*
terraform/*.tfplan
terraform/.terraform.lock.hcl

Python
pycache/
*.py[cod]
.venv/
venv/

Azure Functions
local.settings.json
.python_packages/
.func/

IDE
.vscode/
.idea/
*.swp

OS
.DS_Store
Thumbs.db

Secrets
*.pem
*.key
secrets/
HEREDOC

cat > .env.example << 'HEREDOC'

Azure Configuration
AZURE_SUBSCRIPTION_ID=
AZURE_TENANT_ID=
AZURE_LOCATION=eastus

Project Configuration
PROJECT_NAME=ai-inference-platform
RESOURCE_GROUP_NAME=ai-inference-platform-rg

Key Vault (auto-populated after deployment)
KEY_VAULT_NAME=

API Keys (store in Key Vault, not here)
OPENAI_API_KEY=
SENDGRID_API_KEY=
GITHUB_TOKEN=
HEREDOC

=============================================================================
2. DEPLOY.SH - MAIN DEPLOYMENT SCRIPT
=============================================================================
cat > deploy.sh << 'HEREDOC'
#!/usr/bin/env bash
set -euo pipefail

=============================================================================
CONFIGURATION
=============================================================================
PROJECT_NAME="
P
R
O
J
E
C
T
N
A
M
E
:
âˆ’
a
i
âˆ’
i
n
f
e
r
e
n
c
e
âˆ’
p
l
a
t
f
o
r
m
"
L
O
C
A
T
I
O
N
=
"
PROJECT 
N
â€‹
 AME:âˆ’aiâˆ’inferenceâˆ’platform"LOCATION="{AZURE_LOCATION:-eastus}"
RESOURCE_GROUP="
P
R
O
J
E
C
T
N
A
M
E
âˆ’
r
g
"
K
E
Y
V
A
U
L
T
N
A
M
E
=
"
PROJECT 
N
â€‹
 AMEâˆ’rg"KEY 
V
â€‹
 AULT 
N
â€‹
 AME="{PROJECT_NAME}-kv-
(
d
a
t
e
+
T
A
G
S
=
"
p
r
o
j
e
c
t
=
(date+TAGS="project={PROJECT_NAME} environment=production managed-by=script"

SKUs
APIM_SKU="Consumption"
VMSS_SKU="Standard_NC4as_T4_v3"
SPOT_MAX_PRICE="0.15"

=============================================================================
LOGGING
=============================================================================
log() { echo -e "\033[1;32m[
(
d
a
t
e
+
(date+\033[0m"; }
warn() { echo -e "\033[1;33m[
(
d
a
t
e
+
(date+\033[0m" >&2; }
error() { echo -e "\033[1;31m[
(
d
a
t
e
+
(date+\033[0m" >&2; exit 1; }
info() { echo -e "\033[1;34m[
(
d
a
t
e
+
(date+\033[0m"; }

=============================================================================
PREREQUISITES
=============================================================================
check_prerequisites() {
info "Checking prerequisites..."

text
command -v az &>/dev/null || error "Azure CLI not found. Install: https://aka.ms/installazurecli"
command -v jq &>/dev/null || error "jq not found. Install: apt-get install jq"

if ! az account show &>/dev/null; then
    warn "Not logged into Azure"
    az login
fi

SUBSCRIPTION_ID=$(az account show --query id -o tsv)
log "Using subscription: ${SUBSCRIPTION_ID}"
}

=============================================================================
RESOURCE GROUP
=============================================================================
create_resource_group() {
info "Creating resource group: ${RESOURCE_GROUP}"

text
if az group show --name "${RESOURCE_GROUP}" &>/dev/null; then
    warn "Resource group already exists"
else
    az group create \
        --name "${RESOURCE_GROUP}" \
        --location "${LOCATION}" \
        --tags ${TAGS}
    log "Resource group created"
fi
}

=============================================================================
KEY VAULT (SECRETS MANAGEMENT)
=============================================================================
create_key_vault() {
info "Creating Key Vault for secrets management..."

text
# Check if Key Vault exists
local existing_kv=$(az keyvault list --resource-group "${RESOURCE_GROUP}" --query "[0].name" -o tsv 2>/dev/null || true)

if [[ -n "$existing_kv" ]]; then
    KEY_VAULT_NAME="$existing_kv"
    warn "Using existing Key Vault: ${KEY_VAULT_NAME}"
else
    az keyvault create \
        --name "${KEY_VAULT_NAME}" \
        --resource-group "${RESOURCE_GROUP}" \
        --location "${LOCATION}" \
        --enable-rbac-authorization true \
        --tags ${TAGS}
    
    # Assign Key Vault Administrator role to current user
    local current_user=$(az ad signed-in-user show --query id -o tsv)
    az role assignment create \
        --role "Key Vault Administrator" \
        --assignee "${current_user}" \
        --scope "/subscriptions/${SUBSCRIPTION_ID}/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.KeyVault/vaults/${KEY_VAULT_NAME}"
    
    log "Key Vault created: ${KEY_VAULT_NAME}"
fi

# Store initial secrets
info "Storing initial secrets..."

# Generate API key for inference service
local api_key=$(openssl rand -hex 32)
az keyvault secret set \
    --vault-name "${KEY_VAULT_NAME}" \
    --name "inference-api-key" \
    --value "${api_key}" \
    --tags ${TAGS} &>/dev/null

# Generate internal service key
local internal_key=$(openssl rand -hex 32)
az keyvault secret set \
    --vault-name "${KEY_VAULT_NAME}" \
    --name "internal-service-key" \
    --value "${internal_key}" \
    --tags ${TAGS} &>/dev/null

log "Secrets stored in Key Vault"

echo "KEY_VAULT_NAME=${KEY_VAULT_NAME}" > .env
}

=============================================================================
STORAGE ACCOUNT
=============================================================================
create_storage_account() {
info "Creating storage account..."
local storage_name="
P
R
O
J
E
C
T
N
A
M
E
/
/
[
a
âˆ’
z
0
âˆ’
9
]
/
PROJECT 
N
â€‹
 AME//[ 
a
 âˆ’z0âˆ’9]/(date +%s | tail -c 6)"
storage_name="${storage_name:0:24}" # Max 24 chars

text
if az storage account show --name "${storage_name}" --resource-group "${RESOURCE_GROUP}" &>/dev/null; then
    warn "Storage account already exists"
else
    az storage account create \
        --name "${storage_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --location "${LOCATION}" \
        --sku Standard_LRS \
        --kind StorageV2 \
        --min-tls-version TLS1_2 \
        --tags ${TAGS}
    log "Storage account created: ${storage_name}"
fi

echo "STORAGE_ACCOUNT=${storage_name}" >> .env
STORAGE_ACCOUNT="${storage_name}"
}

=============================================================================
COSMOS DB
=============================================================================
create_cosmos_db() {
info "Creating Cosmos DB (serverless)..."
local cosmos_name="
P
R
O
J
E
C
T
N
A
M
E
/
/
[
a
âˆ’
z
0
âˆ’
9
]
/
c
a
c
h
e
PROJECT 
N
â€‹
 AME//[ 
a
 âˆ’z0âˆ’9]/cache(date +%s | tail -c 6)"

text
if az cosmosdb show --name "${cosmos_name}" --resource-group "${RESOURCE_GROUP}" &>/dev/null; then
    warn "Cosmos DB already exists"
else
    az cosmosdb create \
        --name "${cosmos_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --locations regionName="${LOCATION}" failoverPriority=0 \
        --capabilities EnableServerless \
        --default-consistency-level Eventual \
        --tags ${TAGS}
    
    az cosmosdb sql database create \
        --account-name "${cosmos_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --name "inferencecache"
    
    az cosmosdb sql container create \
        --account-name "${cosmos_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --database-name "inferencecache" \
        --name "responses" \
        --partition-key-path "/modelId" \
        --ttl 3600
    
    log "Cosmos DB created: ${cosmos_name}"
fi

# Store connection string in Key Vault
local cosmos_key=$(az cosmosdb keys list --name "${cosmos_name}" --resource-group "${RESOURCE_GROUP}" --query primaryMasterKey -o tsv)
az keyvault secret set \
    --vault-name "${KEY_VAULT_NAME}" \
    --name "cosmos-db-key" \
    --value "${cosmos_key}" &>/dev/null

echo "COSMOS_ACCOUNT=${cosmos_name}" >> .env
COSMOS_ACCOUNT="${cosmos_name}"
}

=============================================================================
VIRTUAL NETWORK
=============================================================================
create_network() {
info "Creating network infrastructure..."
local vnet_name="
P
R
O
J
E
C
T
N
A
M
E
âˆ’
v
n
e
t
"
l
o
c
a
l
s
u
b
n
e
t
n
a
m
e
=
"
PROJECT 
N
â€‹
 AMEâˆ’vnet"localsubnet 
n
â€‹
 ame="{PROJECT_NAME}-subnet"
local nsg_name="${PROJECT_NAME}-nsg"

text
# NSG
if ! az network nsg show --name "${nsg_name}" --resource-group "${RESOURCE_GROUP}" &>/dev/null; then
    az network nsg create \
        --name "${nsg_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --tags ${TAGS}
    
    # Allow HTTPS from APIM
    az network nsg rule create \
        --nsg-name "${nsg_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --name "Allow-HTTPS-Inbound" \
        --priority 100 \
        --destination-port-ranges 443 8080 \
        --protocol Tcp \
        --source-address-prefixes "AzureCloud" \
        --access Allow
    
    # Allow health checks
    az network nsg rule create \
        --nsg-name "${nsg_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --name "Allow-HealthCheck" \
        --priority 110 \
        --destination-port-ranges 8081 \
        --protocol Tcp \
        --source-address-prefixes "AzureLoadBalancer" \
        --access Allow
    
    log "NSG created"
fi

# VNet
if ! az network vnet show --name "${vnet_name}" --resource-group "${RESOURCE_GROUP}" &>/dev/null; then
    az network vnet create \
        --name "${vnet_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --location "${LOCATION}" \
        --address-prefix 10.0.0.0/16 \
        --subnet-name "${subnet_name}" \
        --subnet-prefix 10.0.1.0/24 \
        --tags ${TAGS}
    
    az network vnet subnet update \
        --name "${subnet_name}" \
        --vnet-name "${vnet_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --network-security-group "${nsg_name}"
    
    log "VNet created"
fi

echo "VNET_NAME=${vnet_name}" >> .env
echo "SUBNET_NAME=${subnet_name}" >> .env
VNET_NAME="${vnet_name}"
SUBNET_NAME="${subnet_name}"
}

=============================================================================
LOG ANALYTICS & APPLICATION INSIGHTS
=============================================================================
create_monitoring() {
info "Creating monitoring resources..."
local workspace_name="
P
R
O
J
E
C
T
N
A
M
E
âˆ’
l
o
g
s
"
l
o
c
a
l
a
p
p
i
n
s
i
g
h
t
s
n
a
m
e
=
"
PROJECT 
N
â€‹
 AMEâˆ’logs"localappinsights 
n
â€‹
 ame="{PROJECT_NAME}-insights"

text
# Log Analytics
if ! az monitor log-analytics workspace show --workspace-name "${workspace_name}" --resource-group "${RESOURCE_GROUP}" &>/dev/null; then
    az monitor log-analytics workspace create \
        --workspace-name "${workspace_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --location "${LOCATION}" \
        --sku PerGB2018 \
        --retention-time 30 \
        --tags ${TAGS}
    log "Log Analytics workspace created"
fi

local workspace_id=$(az monitor log-analytics workspace show --workspace-name "${workspace_name}" --resource-group "${RESOURCE_GROUP}" --query id -o tsv)

# Application Insights
if ! az monitor app-insights component show --app "${appinsights_name}" --resource-group "${RESOURCE_GROUP}" &>/dev/null; then
    az monitor app-insights component create \
        --app "${appinsights_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --location "${LOCATION}" \
        --workspace "${workspace_id}" \
        --application-type web \
        --tags ${TAGS}
    log "Application Insights created"
fi

local instrumentation_key=$(az monitor app-insights component show --app "${appinsights_name}" --resource-group "${RESOURCE_GROUP}" --query instrumentationKey -o tsv)
local connection_string=$(az monitor app-insights component show --app "${appinsights_name}" --resource-group "${RESOURCE_GROUP}" --query connectionString -o tsv)

# Store in Key Vault
az keyvault secret set --vault-name "${KEY_VAULT_NAME}" --name "appinsights-key" --value "${instrumentation_key}" &>/dev/null
az keyvault secret set --vault-name "${KEY_VAULT_NAME}" --name "appinsights-connection" --value "${connection_string}" &>/dev/null

echo "LOG_ANALYTICS_WORKSPACE=${workspace_name}" >> .env
echo "APP_INSIGHTS_NAME=${appinsights_name}" >> .env
APP_INSIGHTS_NAME="${appinsights_name}"
}

=============================================================================
FUNCTION APP
=============================================================================
create_function_app() {
info "Creating Function App..."
local func_name="
P
R
O
J
E
C
T
N
A
M
E
âˆ’
f
u
n
c
"
l
o
c
a
l
f
u
n
c
s
t
o
r
a
g
e
=
"
PROJECT 
N
â€‹
 AMEâˆ’func"localfunc 
s
â€‹
 torage="{PROJECT_NAME//[^a-z0-9]/}fn
(
d
a
t
e
+
f
u
n
c
s
t
o
r
a
g
e
=
"
(date+func 
s
â€‹
 torage="{func_storage:0:24}"

text
# Storage for function app
if ! az storage account show --name "${func_storage}" --resource-group "${RESOURCE_GROUP}" &>/dev/null; then
    az storage account create \
        --name "${func_storage}" \
        --resource-group "${RESOURCE_GROUP}" \
        --location "${LOCATION}" \
        --sku Standard_LRS \
        --kind StorageV2 \
        --tags ${TAGS}
fi

# Function App
if ! az functionapp show --name "${func_name}" --resource-group "${RESOURCE_GROUP}" &>/dev/null; then
    az functionapp create \
        --name "${func_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --storage-account "${func_storage}" \
        --consumption-plan-location "${LOCATION}" \
        --runtime python \
        --runtime-version 3.11 \
        --functions-version 4 \
        --os-type Linux \
        --assign-identity '[system]' \
        --app-insights "${APP_INSIGHTS_NAME}" \
        --tags ${TAGS}
    
    log "Function App created: ${func_name}"
    
    # Grant Key Vault access to Function App
    local func_identity=$(az functionapp identity show --name "${func_name}" --resource-group "${RESOURCE_GROUP}" --query principalId -o tsv)
    
    az role assignment create \
        --role "Key Vault Secrets User" \
        --assignee "${func_identity}" \
        --scope "/subscriptions/${SUBSCRIPTION_ID}/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.KeyVault/vaults/${KEY_VAULT_NAME}"
    
    # Configure app settings to use Key Vault references
    az functionapp config appsettings set \
        --name "${func_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --settings \
            "COSMOS_DB_KEY=@Microsoft.KeyVault(SecretUri=https://${KEY_VAULT_NAME}.vault.azure.net/secrets/cosmos-db-key/)" \
            "INFERENCE_API_KEY=@Microsoft.KeyVault(SecretUri=https://${KEY_VAULT_NAME}.vault.azure.net/secrets/inference-api-key/)" \
            "APPINSIGHTS_INSTRUMENTATIONKEY=@Microsoft.KeyVault(SecretUri=https://${KEY_VAULT_NAME}.vault.azure.net/secrets/appinsights-key/)" \
            "KEY_VAULT_NAME=${KEY_VAULT_NAME}" \
            "COSMOS_ACCOUNT=${COSMOS_ACCOUNT}" \
            "PROJECT_NAME=${PROJECT_NAME}"
    
    log "Function App configured with Key Vault references"
else
    warn "Function App already exists"
fi

echo "FUNCTION_APP_NAME=${func_name}" >> .env
FUNCTION_APP_NAME="${func_name}"
}

=============================================================================
VMSS (GPU INSTANCES)
=============================================================================
create_vmss() {
info "Creating GPU VMSS with spot instances..."
local vmss_name="${PROJECT_NAME}-gpu"

text
if az vmss show --name "${vmss_name}" --resource-group "${RESOURCE_GROUP}" &>/dev/null; then
    warn "VMSS already exists"
    echo "VMSS_NAME=${vmss_name}" >> .env
    return
fi

# Get latest Ubuntu 22.04 image
local image_urn=$(az vm image list \
    --publisher Canonical \
    --offer 0001-com-ubuntu-server-jammy \
    --sku 22_04-lts-gen2 \
    --all \
    --query '[0].urn' -o tsv)

# Create cloud-init script
local cloud_init=$(cat << 'CLOUDINIT'
#!/bin/bash
set -e

Install Docker
apt-get update
apt-get install -y docker.io curl jq

Install NVIDIA drivers and container toolkit
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list |
sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' |
tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

apt-get update
apt-get install -y nvidia-container-toolkit

Configure Docker with NVIDIA runtime
nvidia-ctk runtime configure --runtime=docker
systemctl restart docker

Pull inference server images
docker pull ghcr.io/ggerganov/llama.cpp:server-cuda

Create inference server startup script
cat > /opt/start-inference.sh << 'EOF'
#!/bin/bash
docker run -d --gpus all
--name inference-server
-p 8080:8080
-p 8081:8081
-v /models:/models
--restart unless-stopped
ghcr.io/ggerganov/llama.cpp:server-cuda
--host 0.0.0.0
--port 8080
--metrics-port 8081
EOF
chmod +x /opt/start-inference.sh

Create health check endpoint
cat > /opt/health-check.py << 'EOF'
#!/usr/bin/env python3
from http.server import HTTPServer, BaseHTTPRequestHandler
import json
import subprocess

class HealthHandler(BaseHTTPRequestHandler):
def do_GET(self):
if self.path == '/health/live':
self.send_response(200)
self.send_header('Content-Type', 'application/json')
self.end_headers()
self.wfile.write(json.dumps({"status": "alive"}).encode())
elif self.path == '/health/ready':
# Check if inference server is running
result = subprocess.run(['docker', 'ps', '-q', '-f', 'name=inference-server'], capture_output=True)
if result.stdout:
self.send_response(200)
status = {"status": "ready", "inference_server": "running"}
else:
self.send_response(503)
status = {"status": "not_ready", "inference_server": "stopped"}
self.send_header('Content-Type', 'application/json')
self.end_headers()
self.wfile.write(json.dumps(status).encode())
else:
self.send_response(404)
self.end_headers()

HTTPServer(('0.0.0.0', 8081), HealthHandler).serve_forever()
EOF
chmod +x /opt/health-check.py

Start health check server
nohup python3 /opt/health-check.py > /var/log/health-check.log 2>&1 &

echo "VM initialization complete"
CLOUDINIT
)

text
az vmss create \
    --name "${vmss_name}" \
    --resource-group "${RESOURCE_GROUP}" \
    --location "${LOCATION}" \
    --vm-sku "${VMSS_SKU}" \
    --image "${image_urn}" \
    --vnet-name "${VNET_NAME}" \
    --subnet "${SUBNET_NAME}" \
    --lb "" \
    --instance-count 0 \
    --priority Spot \
    --max-price "${SPOT_MAX_PRICE}" \
    --eviction-policy Deallocate \
    --storage-sku StandardSSD_LRS \
    --admin-username azureuser \
    --generate-ssh-keys \
    --assign-identity '[system]' \
    --custom-data "$(echo "${cloud_init}" | base64 -w0)" \
    --health-probe '{"protocol": "http", "port": 8081, "requestPath": "/health/ready"}' \
    --upgrade-policy-mode Automatic \
    --tags ${TAGS}

# Grant VMSS identity access to Key Vault
local vmss_identity=$(az vmss identity show --name "${vmss_name}" --resource-group "${RESOURCE_GROUP}" --query principalId -o tsv)
az role assignment create \
    --role "Key Vault Secrets User" \
    --assignee "${vmss_identity}" \
    --scope "/subscriptions/${SUBSCRIPTION_ID}/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.KeyVault/vaults/${KEY_VAULT_NAME}"

log "VMSS created: ${vmss_name}"

echo "VMSS_NAME=${vmss_name}" >> .env
VMSS_NAME="${vmss_name}"
}

=============================================================================
API MANAGEMENT
=============================================================================
create_apim() {
info "Creating API Management..."
local apim_name="${PROJECT_NAME}-apim"

text
if az apim show --name "${apim_name}" --resource-group "${RESOURCE_GROUP}" &>/dev/null; then
    warn "API Management already exists"
    echo "APIM_NAME=${apim_name}" >> .env
    return
fi

az apim create \
    --name "${apim_name}" \
    --resource-group "${RESOURCE_GROUP}" \
    --location "${LOCATION}" \
    --publisher-email "admin@${PROJECT_NAME}.example.com" \
    --publisher-name "${PROJECT_NAME}" \
    --sku-name "${APIM_SKU}" \
    --tags ${TAGS}

log "API Management created: ${apim_name}"

# Import API definition
if [[ -f "openapi.json" ]]; then
    az apim api import \
        --service-name "${apim_name}" \
        --resource-group "${RESOURCE_GROUP}" \
        --api-id "inference-v1" \
        --specification-format OpenApi \
        --specification-path "openapi.json" \
        --path "/v1" \
        --api-type http
    
    log "API imported to APIM"
fi

echo "APIM_NAME=${apim_name}" >> .env
APIM_NAME="${apim_name}"
}

=============================================================================
AUTOSCALING
=============================================================================
create_autoscaling() {
info "Configuring autoscaling..."

text
az monitor autoscale create \
    --resource-group "${RESOURCE_GROUP}" \
    --resource "${VMSS_NAME}" \
    --resource-type Microsoft.Compute/virtualMachineScaleSets \
    --name "${VMSS_NAME}-autoscale" \
    --min-count 0 \
    --max-count 20 \
    --count 0 \
    --tags ${TAGS}

# Scale out on high CPU
az monitor autoscale rule create \
    --autoscale-name "${VMSS_NAME}-autoscale" \
    --resource-group "${RESOURCE_GROUP}" \
    --condition "Percentage CPU > 70 avg 5m" \
    --scale out 2

# Scale in on low CPU
az monitor autoscale rule create \
    --autoscale-name "${VMSS_NAME}-autoscale" \
    --resource-group "${RESOURCE_GROUP}" \
    --condition "Percentage CPU < 20 avg 10m" \
    --scale in 1

# Scale out on queue length (if using Service Bus)
az monitor autoscale rule create \
    --autoscale-name "${VMSS_NAME}-autoscale" \
    --resource-group "${RESOURCE_GROUP}" \
    --condition "Percentage CPU > 80 avg 2m" \
    --scale out 4

log "Autoscaling configured"
}

=============================================================================
MAIN
=============================================================================
main() {
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo " AI Inference Arbitrage Platform - Deployment"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

text
check_prerequisites
create_resource_group
create_key_vault
create_storage_account
create_monitoring
create_cosmos_db
create_network
create_function_app
create_vmss
create_apim
create_autoscaling

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
log "Deployment complete!"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "ðŸ“‹ Resources created:"
cat .env
echo ""
echo "ðŸ”— Endpoints:"
echo "   API: https://${APIM_NAME}.azure-api.net/v1"
echo "   Function: https://${FUNCTION_APP_NAME}.azurewebsites.net"
echo "   Key Vault: https://${KEY_VAULT_NAME}.vault.azure.net"
echo ""
echo "ðŸ“– Next steps:"
echo "   1. Deploy function code: func azure functionapp publish ${FUNCTION_APP_NAME}"
echo "   2. Import API to APIM: az apim api import ..."
echo "   3. Configure DNS and SSL"
echo ""
}

main "$@"
HEREDOC
chmod +x deploy.sh

=============================================================================
3. OPENAPI SPECIFICATION
=============================================================================
cat > openapi.json << 'HEREDOC'
{
"openapi": "3.0.3",
"info": {
"title": "AI Inference API",
"description": "High-performance AI inference API with OpenAI-compatible endpoints",
"version": "1.0.0",
"contact": {
"name": "API Support",
"email": "support@example.com"
}
},
"servers": [
{
"url": "https://{apim-name}.azure-api.net/v1",
"description": "Production API"
}
],
"paths": {
"/chat/completions": {
"post": {
"summary": "Create chat completion",
"operationId": "createChatCompletion",
"tags": ["Chat"],
"security": [{"bearerAuth": []}],
"requestBody": {
"required": true,
"content": {
"application/json": {
"schema": {"ref": "#/components/schemas/ChatCompletionRequest"} } } }, "responses": { "200": { "description": "Successful response", "content": { "application/json": { "schema": {"ref": "#/components/schemas/ChatCompletionResponse"}
}
}
},
"400": {"ref": "#/components/responses/BadRequest"}, "401": {"ref": "#/components/responses/Unauthorized"},
"429": {"ref": "#/components/responses/RateLimited"}, "500": {"ref": "#/components/responses/InternalError"}
}
}
},
"/models": {
"get": {
"summary": "List available models",
"operationId": "listModels",
"tags": ["Models"],
"security": [{"bearerAuth": []}],
"responses": {
"200": {
"description": "List of models",
"content": {
"application/json": {
"schema": {"ref": "#/components/schemas/ModelList"} } } } } } }, "/health/live": { "get": { "summary": "Liveness probe", "operationId": "healthLive", "tags": ["Health"], "responses": { "200": { "description": "Service is alive", "content": { "application/json": { "schema": {"ref": "#/components/schemas/HealthResponse"}
}
}
}
}
}
},
"/health/ready": {
"get": {
"summary": "Readiness probe",
"operationId": "healthReady",
"tags": ["Health"],
"responses": {
"200": {
"description": "Service is ready",
"content": {
"application/json": {
"schema": {"ref": "#/components/schemas/HealthResponse"} } } }, "503": { "description": "Service not ready", "content": { "application/json": { "schema": {"ref": "#/components/schemas/HealthResponse"}
}
}
}
}
}
}
},
"components": {
"securitySchemes": {
"bearerAuth": {
"type": "http",
"scheme": "bearer"
}
},
"schemas": {
"ChatCompletionRequest": {
"type": "object",
"required": ["model", "messages"],
"properties": {
"model": {
"type": "string",
"enum": ["mixtral-8x7b", "llama-3-70b", "phi-3-mini", "auto"],
"description": "Model to use for completion"
},
"messages": {
"type": "array",
"items": {"ref": "#/components/schemas/Message"} }, "max_tokens": { "type": "integer", "default": 256, "maximum": 4096 }, "temperature": { "type": "number", "default": 1.0, "minimum": 0, "maximum": 2 }, "top_p": { "type": "number", "default": 1.0 }, "stream": { "type": "boolean", "default": false }, "stop": { "oneOf": [ {"type": "string"}, {"type": "array", "items": {"type": "string"}} ] } } }, "Message": { "type": "object", "required": ["role", "content"], "properties": { "role": { "type": "string", "enum": ["system", "user", "assistant"] }, "content": { "type": "string" } } }, "ChatCompletionResponse": { "type": "object", "properties": { "id": {"type": "string"}, "object": {"type": "string", "default": "chat.completion"}, "created": {"type": "integer"}, "model": {"type": "string"}, "choices": { "type": "array", "items": {"ref": "#/components/schemas/Choice"}
},
"usage": {"ref": "#/components/schemas/Usage"} } }, "Choice": { "type": "object", "properties": { "index": {"type": "integer"}, "message": {"ref": "#/components/schemas/Message"},
"finish_reason": {"type": "string"}
}
},
"Usage": {
"type": "object",
"properties": {
"prompt_tokens": {"type": "integer"},
"completion_tokens": {"type": "integer"},
"total_tokens": {"type": "integer"}
}
},
"ModelList": {
"type": "object",
"properties": {
"object": {"type": "string", "default": "list"},
"data": {
"type": "array",
"items": {"ref": "#/components/schemas/Model"} } } }, "Model": { "type": "object", "properties": { "id": {"type": "string"}, "object": {"type": "string", "default": "model"}, "created": {"type": "integer"}, "owned_by": {"type": "string"} } }, "HealthResponse": { "type": "object", "properties": { "status": {"type": "string", "enum": ["healthy", "unhealthy", "degraded"]}, "timestamp": {"type": "string", "format": "date-time"}, "version": {"type": "string"}, "checks": { "type": "object", "additionalProperties": { "type": "object", "properties": { "status": {"type": "string"}, "latency_ms": {"type": "number"} } } } } }, "Error": { "type": "object", "properties": { "error": { "type": "object", "properties": { "code": {"type": "string"}, "message": {"type": "string"}, "type": {"type": "string"} } } } } }, "responses": { "BadRequest": { "description": "Bad request", "content": { "application/json": { "schema": {"ref": "#/components/schemas/Error"}
}
}
},
"Unauthorized": {
"description": "Unauthorized",
"content": {
"application/json": {
"schema": {"ref": "#/components/schemas/Error"} } } }, "RateLimited": { "description": "Rate limit exceeded", "headers": { "Retry-After": { "schema": {"type": "integer"}, "description": "Seconds to wait before retrying" }, "X-RateLimit-Limit": { "schema": {"type": "integer"} }, "X-RateLimit-Remaining": { "schema": {"type": "integer"} }, "X-RateLimit-Reset": { "schema": {"type": "integer"} } }, "content": { "application/json": { "schema": {"ref": "#/components/schemas/Error"}
}
}
},
"InternalError": {
"description": "Internal server error",
"content": {
"application/json": {
"schema": {"$ref": "#/components/schemas/Error"}
}
}
}
}
}
}
HEREDOC

=============================================================================
4. FUNCTION APP SOURCE CODE
=============================================================================
cat > src/requirements.txt << 'HEREDOC'
azure-functions==1.17.0
azure-identity==1.15.0
azure-keyvault-secrets==4.7.0
azure-cosmos==4.5.1
azure-mgmt-compute==30.3.0
aiohttp==3.9.1
opentelemetry-api==1.22.0
opentelemetry-sdk==1.22.0
opentelemetry-instrumentation==0.43b0
pydantic==2.5.2
HEREDOC

cat > src/host.json << 'HEREDOC'
{
"version": "2.0",
"logging": {
"applicationInsights": {
"samplingSettings": {
"isEnabled": true,
"excludedTypes": "Request"
}
},
"logLevel": {
"default": "Information",
"Host.Results": "Error",
"Function": "Information",
"Host.Aggregator": "Trace"
}
},
"extensions": {
"http": {
"routePrefix": "",
"maxOutstandingRequests": 200,
"maxConcurrentRequests": 100
}
},
"healthMonitor": {
"enabled": true,
"healthCheckInterval": "00:00:10",
"healthCheckWindow": "00:02:00",
"healthCheckThreshold": 6,
"counterThreshold": 0.80
},
"functionTimeout": "00:05:00"
}
HEREDOC

cat > src/local.settings.json.example << 'HEREDOC'
{
"IsEncrypted": false,
"Values": {
"AzureWebJobsStorage": "UseDevelopmentStorage=true",
"FUNCTIONS_WORKER_RUNTIME": "python",
"KEY_VAULT_NAME": "your-keyvault-name",
"COSMOS_ACCOUNT": "your-cosmos-account",
"PROJECT_NAME": "ai-inference-platform"
}
}
HEREDOC

Health check functions
cat > src/health/init.py << 'HEREDOC'
"""Health check endpoints for liveness and readiness probes."""
HEREDOC

cat > src/health/function.json << 'HEREDOC'
{
"scriptFile": "health_functions.py",
"bindings": [
{
"authLevel": "anonymous",
"type": "httpTrigger",
"direction": "in",
"name": "req",
"methods": ["get"],
"route": "health/{check_type}"
},
{
"type": "http",
"direction": "out",
"name": "$return"
}
]
}
HEREDOC

cat > src/health/health_functions.py << 'HEREDOC'
"""Health check functions for Kubernetes-style probes."""

import json
import logging
import os
from datetime import datetime
from typing import Dict, Any

import azure.functions as func
from azure.identity import DefaultAzureCredential
from azure.keyvault.secrets import SecretClient
from azure.cosmos import CosmosClient

logger = logging.getLogger(name)

Cache for health check results
_health_cache: Dict[str, Any] = {}
_cache_ttl = 10 # seconds

async def check_keyvault() -> Dict[str, Any]:
"""Check Key Vault connectivity."""
try:
kv_name = os.environ.get("KEY_VAULT_NAME")
if not kv_name:
return {"status": "skip", "message": "KEY_VAULT_NAME not set"}

text
    credential = DefaultAzureCredential()
    client = SecretClient(
        vault_url=f"https://{kv_name}.vault.azure.net",
        credential=credential
    )
    # Try to list secrets (lightweight operation)
    list(client.list_properties_of_secrets(max_page_size=1))
    return {"status": "healthy", "latency_ms": 0}
except Exception as e:
    logger.error(f"Key Vault health check failed: {e}")
    return {"status": "unhealthy", "error": str(e)}
async def check_cosmos() -> Dict[str, Any]:
"""Check Cosmos DB connectivity."""
try:
cosmos_account = os.environ.get("COSMOS_ACCOUNT")
if not cosmos_account:
return {"status": "skip", "message": "COSMOS_ACCOUNT not set"}

text
    # Use managed identity
    credential = DefaultAzureCredential()
    # Note: In production, you'd use the actual connection
    return {"status": "healthy", "latency_ms": 0}
except Exception as e:
    logger.error(f"Cosmos DB health check failed: {e}")
    return {"status": "unhealthy", "error": str(e)}
async def check_inference_backend() -> Dict[str, Any]:
"""Check inference backend availability."""
try:
# In production, ping the VMSS load balancer
return {"status": "healthy", "instances": 0, "latency_ms": 0}
except Exception as e:
logger.error(f"Inference backend health check failed: {e}")
return {"status": "unhealthy", "error": str(e)}

def main(req: func.HttpRequest) -> func.HttpResponse:
"""
Health check endpoint supporting:
- /health/live - Liveness probe (is the service running?)
- /health/ready - Readiness probe (is the service ready to accept traffic?)
- /health/startup - Startup probe (has the service started?)
"""
check_type = req.route_params.get("check_type", "live")

text
response = {
    "status": "healthy",
    "timestamp": datetime.utcnow().isoformat() + "Z",
    "version": os.environ.get("WEBSITE_INSTANCE_ID", "local"),
    "checks": {}
}

status_code = 200

if check_type == "live":
    # Liveness: Just check if the function is responding
    response["checks"]["self"] = {"status": "healthy"}
    
elif check_type == "ready":
    # Readiness: Check all dependencies
    import asyncio
    
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    try:
        # Run health checks
        kv_result = loop.run_until_complete(check_keyvault())
        cosmos_result = loop.run_until_complete(check_cosmos())
        backend_result = loop.run_until_complete(check_inference_backend())
        
        response["checks"] = {
            "keyvault": kv_result,
            "cosmos": cosmos_result,
            "inference_backend": backend_result
        }
        
        # Determine overall status
        unhealthy = [k for k, v in response["checks"].items() 
                    if v.get("status") == "unhealthy"]
        
        if unhealthy:
            response["status"] = "unhealthy"
            status_code = 503
        elif any(v.get("status") == "degraded" for v in response["checks"].values()):
            response["status"] = "degraded"
            status_code = 200
            
    finally:
        loop.close()
        
elif check_type == "startup":
    # Startup: Check if initial setup is complete
    response["checks"]["initialization"] = {"status": "healthy"}
    
else:
    return func.HttpResponse(
        json.dumps({"error": f"Unknown check type: {check_type}"}),
        status_code=400,
        mimetype="application/json"
    )

return func.HttpResponse(
    json.dumps(response, indent=2),
    status_code=status_code,
    mimetype="application/json",
    headers={
        "Cache-Control": "no-cache, no-store, must-revalidate",
        "X-Health-Check": check_type
    }
)
HEREDOC

API Orchestrator
cat > src/api_orchestrator/init.py << 'HEREDOC'
"""API Orchestrator - Routes requests to optimal inference backend."""
HEREDOC

cat > src/api_orchestrator/function.json << 'HEREDOC'
{
"scriptFile": "main.py",
"bindings": [
{
"authLevel": "function",
"type": "httpTrigger",
"direction": "in",
"name": "req",
"methods": ["post"],
"route": "v1/chat/completions"
},
{
"type": "http",
"direction": "out",
"name": "$return"
}
]
}
HEREDOC

cat > src/api_orchestrator/main.py << 'HEREDOC'
"""
Chat Completions API - OpenAI-compatible endpoint.
Routes requests to optimal inference backend based on model and load.
"""

import json
import logging
import os
import time
import hashlib
from datetime import datetime
from typing import Dict, Any, Optional, List

import azure.functions as func
from azure.identity import DefaultAzureCredential
from azure.keyvault.secrets import SecretClient
from azure.cosmos import CosmosClient
import aiohttp

logger = logging.getLogger(name)

Model configuration
MODELS = {
"mixtral-8x7b": {
"context_length": 32768,
"price_per_1k_tokens": 0.002,
"priority": 1
},
"llama-3-70b": {
"context_length": 8192,
"price_per_1k_tokens": 0.003,
"priority": 2
},
"phi-3-mini": {
"context_length": 4096,
"price_per_1k_tokens": 0.0005,
"priority": 0
}
}

class SecretsManager:
"""Manages secrets from Azure Key Vault with caching."""

text
_instance = None
_secrets_cache: Dict[str, str] = {}

def __new__(cls):
    if cls._instance is None:
        cls._instance = super().__new__(cls)
        cls._instance._initialized = False
    return cls._instance

def _initialize(self):
    if not self._initialized:
        kv_name = os.environ.get("KEY_VAULT_NAME")
        if kv_name:
            credential = DefaultAzureCredential()
            self._client = SecretClient(
                vault_url=f"https://{kv_name}.vault.azure.net",
                credential=credential
            )
        else:
            self._client = None
        self._initialized = True

def get_secret(self, name: str) -> Optional[str]:
    self._initialize()
    
    if name in self._secrets_cache:
        return self._secrets_cache[name]
    
    if self._client:
        try:
            secret = self._client.get_secret(name)
            self._secrets_cache[name] = secret.value
            return secret.value
        except Exception as e:
            logger.error(f"Failed to get secret {name}: {e}")
    
    return os.environ.get(name.upper().replace("-", "_"))
class CacheManager:
"""Manages response caching with Cosmos DB."""

text
def __init__(self):
    self.cosmos_account = os.environ.get("COSMOS_ACCOUNT")
    self._client = None
    
def _get_client(self):
    if self._client is None and self.cosmos_account:
        # In production, use managed identity
        credential = DefaultAzureCredential()
        self._client = CosmosClient(
            url=f"https://{self.cosmos_account}.documents.azure.com:443/",
            credential=credential
        )
    return self._client

def _generate_cache_key(self, request: Dict) -> str:
    """Generate deterministic cache key from request."""
    # Normalize request for caching
    cache_data = {
        "model": request.get("model"),
        "messages": request.get("messages"),
        "temperature": request.get("temperature", 1.0),
        "max_tokens": request.get("max_tokens", 256)
    }
    return hashlib.sha256(
        json.dumps(cache_data, sort_keys=True).encode()
    ).hexdigest()[:32]

async def get_cached_response(self, request: Dict) -> Optional[Dict]:
    """Try to get cached response."""
    try:
        client = self._get_client()
        if not client:
            return None
            
        cache_key = self._generate_cache_key(request)
        database = client.get_database_client("inferencecache")
        container = database.get_container_client("responses")
        
        try:
            item = container.read_item(
                item=cache_key,
                partition_key=request.get("model", "default")
            )
            logger.info(f"Cache hit for key: {cache_key[:8]}...")
            return item.get("response")
        except Exception:
            return None
            
    except Exception as e:
        logger.warning(f"Cache lookup failed: {e}")
        return None

async def set_cached_response(self, request: Dict, response: Dict):
    """Store response in cache."""
    try:
        client = self._get_client()
        if not client:
            return
            
        cache_key = self._generate_cache_key(request)
        database = client.get_database_client("inferencecache")
        container = database.get_container_client("responses")
        
        container.upsert_item({
            "id": cache_key,
            "modelId": request.get("model", "default"),
            "response": response,
            "created_at": datetime.utcnow().isoformat(),
            "ttl": 3600  # 1 hour
        })
        logger.info(f"Cached response for key: {cache_key[:8]}...")
        
    except Exception as e:
        logger.warning(f"Cache write failed: {e}")
class ModelRouter:
"""Routes requests to optimal model/backend."""

text
def __init__(self):
    self.backends: Dict[str, List[str]] = {}
    
def select_model(self, requested_model: str, messages: List[Dict]) -> str:
    """Select optimal model based on request."""
    if requested_model != "auto":
        return requested_model
        
    # Calculate token estimate
    total_chars = sum(len(m.get("content", "")) for m in messages)
    estimated_tokens = total_chars // 4
    
    # Select based on context length needs
    if estimated_tokens > 4000:
        return "mixtral-8x7b"
    elif estimated_tokens > 2000:
        return "llama-3-70b"
    else:
        return "phi-3-mini"  # Cheapest for short prompts

def get_backend_url(self, model: str) -> str:
    """Get backend URL for model."""
    # In production, this would query VMSS for healthy instances
    vmss_name = os.environ.get("VMSS_NAME", "localhost")
    return f"http://{vmss_name}.internal:8080/v1/chat/completions"
Initialize singletons
secrets_manager = SecretsManager()
cache_manager = CacheManager()
model_router = ModelRouter()

async def forward_to_backend(url: str, request: Dict, headers: Dict) -> Dict:
"""Forward request to inference backend."""
async with aiohttp.ClientSession() as session:
async with session.post(
url,
json=request,
headers=headers,
timeout=aiohttp.ClientTimeout(total=120)
) as response:
return await response.json()

def main(req: func.HttpRequest) -> func.HttpResponse:
"""Main handler for chat completions."""
start_time = time.time()
request_id = req.headers.get("X-Request-ID", f"req-{int(time.time()*1000)}")

text
try:
    # Parse request
    try:
        body = req.get_json()
    except ValueError:
        return func.HttpResponse(
            json.dumps({
                "error": {
                    "code": "invalid_request",
                    "message": "Invalid JSON in request body"
                }
            }),
            status_code=400,
            mimetype="application/json"
        )
    
    # Validate required fields
    if "messages" not in body:
        return func.HttpResponse(
            json.dumps({
                "error": {
                    "code": "invalid_request",
                    "message": "messages field is required"
                }
            }),
            status_code=400,
            mimetype="application/json"
        )
    
    # Select model
    requested_model = body.get("model", "auto")
    selected_model = model_router.select_model(
        requested_model, 
        body.get("messages", [])
    )
    body["model"] = selected_model
    
    # Check cache (for non-streaming requests)
    if not body.get("stream", False):
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            cached = loop.run_until_complete(
                cache_manager.get_cached_response(body)
            )
            if cached:
                cached["_cached"] = True
                return func.HttpResponse(
                    json.dumps(cached),
                    status_code=200,
                    mimetype="application/json",
                    headers={
                        "X-Request-ID": request_id,
                        "X-Cache": "HIT",
                        "X-Model": selected_model,
                        "X-Duration-Ms": str(int((time.time() - start_time) * 1000))
                    }
                )
        finally:
            loop.close()
    
    # Forward to backend
    backend_url = model_router.get_backend_url(selected_model)
    internal_key = secrets_manager.get_secret("internal-service-key")
    
    import asyncio
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    try:
        response = loop.run_until_complete(
            forward_to_backend(
                backend_url,
                body,
                {"Authorization": f"Bearer {internal_key}"}
            )
        )
        
        # Cache successful response
        if not body.get("stream", False):
            loop.run_until_complete(
                cache_manager.set_cached_response(body, response)
            )
            
    finally:
        loop.close()
    
    duration_ms = int((time.time() - start_time) * 1000)
    
    return func.HttpResponse(
        json.dumps(response),
        status_code=200,
        mimetype="application/json",
        headers={
            "X-Request-ID": request_id,
            "X-Cache": "MISS",
            "X-Model": selected_model,
            "X-Duration-Ms": str(duration_ms)
        }
    )
    
except Exception as e:
    logger.exception(f"Request failed: {e}")
    return func.HttpResponse(
        json.dumps({
            "error": {
                "code": "internal_error",
                "message": "An internal error occurred",
                "request_id": request_id
            }
        }),
        status_code=500,
        mimetype="application/json"
    )
HEREDOC

Models endpoint
mkdir -p src/models_list
cat > src/models_list/function.json << 'HEREDOC'
{
"scriptFile": "main.py",
"bindings": [
{
"authLevel": "function",
"type": "httpTrigger",
"direction": "in",
"name": "req",
"methods": ["get"],
"route": "v1/models"
},
{
"type": "http",
"direction": "out",
"name": "$return"
}
]
}
HEREDOC

cat > src/models_list/main.py << 'HEREDOC'
"""List available models endpoint."""

import json
import time
import azure.functions as func

MODELS = [
{
"id": "mixtral-8x7b",
"object": "model",
"created": 1700000000,
"owned_by": "mistralai",
"context_length": 32768,
"pricing": {"prompt": 0.002, "completion": 0.002}
},
{
"id": "llama-3-70b",
"object": "model",
"created": 1700000000,
"owned_by": "meta",
"context_length": 8192,
"pricing": {"prompt": 0.003, "completion": 0.003}
},
{
"id": "phi-3-mini",
"object": "model",
"created": 1700000000,
"owned_by": "microsoft",
"context_length": 4096,
"pricing": {"prompt": 0.0005, "completion": 0.0005}
}
]

def main(req: func.HttpRequest) -> func.HttpResponse:
return func.HttpResponse(
json.dumps({
"object": "list",
"data": MODELS
}),
status_code=200,
mimetype="application/json"
)
HEREDOC

=============================================================================
5. TERRAFORM CONFIGURATION
=============================================================================
cat > terraform/main.tf << 'HEREDOC'

=============================================================================
AI Inference Arbitrage Platform - Terraform Configuration
=============================================================================
terraform {
required_version = ">= 1.5.0"

required_providers {
azurerm = {
source = "hashicorp/azurerm"
version = "> 3.80"
}
azuread = {
source = "hashicorp/azuread"
version = "> 2

Claude Opus 4.5
continue


Thought Process
expand
bash
# Continuing from terraform/main.tf...

cat > terraform/main.tf << 'HEREDOC'
# =============================================================================
# AI Inference Arbitrage Platform - Terraform Configuration
# =============================================================================

terraform {
  required_version = ">= 1.5.0"
  
  required_providers {
    azurerm = {
      source  = "hashicorp/azurerm"
      version = "~> 3.80"
    }
    azuread = {
      source  = "hashicorp/azuread"
      version = "~> 2.45"
    }
    random = {
      source  = "hashicorp/random"
      version = "~> 3.5"
    }
  }
  
  backend "azurerm" {
    # Configure in backend.tfvars or via CLI
    # storage_account_name = "tfstate..."
    # container_name       = "tfstate"
    # key                  = "ai-inference.tfstate"
  }
}

provider "azurerm" {
  features {
    key_vault {
      purge_soft_delete_on_destroy    = false
      recover_soft_deleted_key_vaults = true
    }
    resource_group {
      prevent_deletion_if_contains_resources = false
    }
  }
}

provider "azuread" {}

# =============================================================================
# DATA SOURCES
# =============================================================================

data "azurerm_client_config" "current" {}

data "azuread_client_config" "current" {}

# =============================================================================
# RANDOM SUFFIXES
# =============================================================================

resource "random_string" "suffix" {
  length  = 6
  special = false
  upper   = false
}

# =============================================================================
# LOCALS
# =============================================================================

locals {
  name_suffix = random_string.suffix.result
  
  tags = {
    project     = var.project_name
    environment = var.environment
    managed_by  = "terraform"
    cost_center = "ai-inference"
  }
  
  # Resource names
  resource_group_name    = "${var.project_name}-${var.environment}-rg"
  key_vault_name         = "${var.project_name}-kv-${local.name_suffix}"
  storage_account_name   = "${replace(var.project_name, "-", "")}st${local.name_suffix}"
  cosmos_account_name    = "${var.project_name}-cosmos-${local.name_suffix}"
  function_app_name      = "${var.project_name}-func-${local.name_suffix}"
  app_insights_name      = "${var.project_name}-insights"
  log_analytics_name     = "${var.project_name}-logs"
  apim_name              = "${var.project_name}-apim"
  vnet_name              = "${var.project_name}-vnet"
  vmss_name              = "${var.project_name}-gpu"
}
HEREDOC

cat > terraform/variables.tf << 'HEREDOC'
# =============================================================================
# VARIABLES
# =============================================================================

variable "project_name" {
  description = "Project name (used for resource naming)"
  type        = string
  default     = "ai-inference"
  
  validation {
    condition     = can(regex("^[a-z0-9-]+$", var.project_name))
    error_message = "Project name must contain only lowercase letters, numbers, and hyphens."
  }
}

variable "environment" {
  description = "Environment (dev, staging, prod)"
  type        = string
  default     = "prod"
  
  validation {
    condition     = contains(["dev", "staging", "prod"], var.environment)
    error_message = "Environment must be dev, staging, or prod."
  }
}

variable "location" {
  description = "Azure region"
  type        = string
  default     = "eastus"
}

variable "vmss_sku" {
  description = "VM SKU for GPU instances"
  type        = string
  default     = "Standard_NC4as_T4_v3"
}

variable "vmss_spot_max_price" {
  description = "Maximum price for spot instances (-1 for on-demand price)"
  type        = number
  default     = 0.15
}

variable "vmss_min_instances" {
  description = "Minimum VMSS instances"
  type        = number
  default     = 0
}

variable "vmss_max_instances" {
  description = "Maximum VMSS instances"
  type        = number
  default     = 20
}

variable "admin_email" {
  description = "Admin email for APIM and alerts"
  type        = string
  default     = "admin@example.com"
}

variable "enable_ddos_protection" {
  description = "Enable DDoS protection (additional cost)"
  type        = bool
  default     = false
}
HEREDOC

cat > terraform/resource_group.tf << 'HEREDOC'
# =============================================================================
# RESOURCE GROUP
# =============================================================================

resource "azurerm_resource_group" "main" {
  name     = local.resource_group_name
  location = var.location
  tags     = local.tags
}
HEREDOC

cat > terraform/keyvault.tf << 'HEREDOC'
# =============================================================================
# KEY VAULT
# =============================================================================

resource "azurerm_key_vault" "main" {
  name                = local.key_vault_name
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  tenant_id           = data.azurerm_client_config.current.tenant_id
  sku_name            = "standard"
  
  enable_rbac_authorization       = true
  enabled_for_deployment          = true
  enabled_for_template_deployment = true
  soft_delete_retention_days      = 7
  purge_protection_enabled        = false
  
  network_acls {
    default_action = "Allow"
    bypass         = "AzureServices"
  }
  
  tags = local.tags
}

# Grant current user Key Vault Administrator
resource "azurerm_role_assignment" "kv_admin" {
  scope                = azurerm_key_vault.main.id
  role_definition_name = "Key Vault Administrator"
  principal_id         = data.azurerm_client_config.current.object_id
}

# Generate and store API key
resource "random_password" "api_key" {
  length  = 64
  special = false
}

resource "azurerm_key_vault_secret" "inference_api_key" {
  name         = "inference-api-key"
  value        = random_password.api_key.result
  key_vault_id = azurerm_key_vault.main.id
  
  depends_on = [azurerm_role_assignment.kv_admin]
}

# Generate internal service key
resource "random_password" "internal_key" {
  length  = 64
  special = false
}

resource "azurerm_key_vault_secret" "internal_service_key" {
  name         = "internal-service-key"
  value        = random_password.internal_key.result
  key_vault_id = azurerm_key_vault.main.id
  
  depends_on = [azurerm_role_assignment.kv_admin]
}
HEREDOC

cat > terraform/monitoring.tf << 'HEREDOC'
# =============================================================================
# MONITORING (Log Analytics + Application Insights)
# =============================================================================

resource "azurerm_log_analytics_workspace" "main" {
  name                = local.log_analytics_name
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  sku                 = "PerGB2018"
  retention_in_days   = 30
  
  tags = local.tags
}

resource "azurerm_application_insights" "main" {
  name                = local.app_insights_name
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  workspace_id        = azurerm_log_analytics_workspace.main.id
  application_type    = "web"
  
  tags = local.tags
}

# Store instrumentation key in Key Vault
resource "azurerm_key_vault_secret" "appinsights_key" {
  name         = "appinsights-key"
  value        = azurerm_application_insights.main.instrumentation_key
  key_vault_id = azurerm_key_vault.main.id
  
  depends_on = [azurerm_role_assignment.kv_admin]
}

resource "azurerm_key_vault_secret" "appinsights_connection" {
  name         = "appinsights-connection"
  value        = azurerm_application_insights.main.connection_string
  key_vault_id = azurerm_key_vault.main.id
  
  depends_on = [azurerm_role_assignment.kv_admin]
}
HEREDOC

cat > terraform/storage.tf << 'HEREDOC'
# =============================================================================
# STORAGE ACCOUNTS
# =============================================================================

# Main storage account
resource "azurerm_storage_account" "main" {
  name                     = local.storage_account_name
  resource_group_name      = azurerm_resource_group.main.name
  location                 = azurerm_resource_group.main.location
  account_tier             = "Standard"
  account_replication_type = "LRS"
  min_tls_version          = "TLS1_2"
  
  blob_properties {
    delete_retention_policy {
      days = 7
    }
  }
  
  tags = local.tags
}

# Function app storage
resource "azurerm_storage_account" "functions" {
  name                     = "${replace(var.project_name, "-", "")}fn${local.name_suffix}"
  resource_group_name      = azurerm_resource_group.main.name
  location                 = azurerm_resource_group.main.location
  account_tier             = "Standard"
  account_replication_type = "LRS"
  min_tls_version          = "TLS1_2"
  
  tags = local.tags
}
HEREDOC

cat > terraform/cosmos.tf << 'HEREDOC'
# =============================================================================
# COSMOS DB (Serverless)
# =============================================================================

resource "azurerm_cosmosdb_account" "main" {
  name                = local.cosmos_account_name
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  offer_type          = "Standard"
  kind                = "GlobalDocumentDB"
  
  consistency_policy {
    consistency_level = "Eventual"
  }
  
  capabilities {
    name = "EnableServerless"
  }
  
  geo_location {
    location          = azurerm_resource_group.main.location
    failover_priority = 0
  }
  
  tags = local.tags
}

resource "azurerm_cosmosdb_sql_database" "cache" {
  name                = "inferencecache"
  resource_group_name = azurerm_resource_group.main.name
  account_name        = azurerm_cosmosdb_account.main.name
}

resource "azurerm_cosmosdb_sql_container" "responses" {
  name                = "responses"
  resource_group_name = azurerm_resource_group.main.name
  account_name        = azurerm_cosmosdb_account.main.name
  database_name       = azurerm_cosmosdb_sql_database.cache.name
  partition_key_path  = "/modelId"
  default_ttl         = 3600
}

# Store Cosmos key in Key Vault
resource "azurerm_key_vault_secret" "cosmos_key" {
  name         = "cosmos-db-key"
  value        = azurerm_cosmosdb_account.main.primary_key
  key_vault_id = azurerm_key_vault.main.id
  
  depends_on = [azurerm_role_assignment.kv_admin]
}
HEREDOC

cat > terraform/network.tf << 'HEREDOC'
# =============================================================================
# NETWORKING
# =============================================================================

resource "azurerm_virtual_network" "main" {
  name                = local.vnet_name
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  address_space       = ["10.0.0.0/16"]
  
  tags = local.tags
}

resource "azurerm_subnet" "vmss" {
  name                 = "vmss-subnet"
  resource_group_name  = azurerm_resource_group.main.name
  virtual_network_name = azurerm_virtual_network.main.name
  address_prefixes     = ["10.0.1.0/24"]
}

resource "azurerm_subnet" "functions" {
  name                 = "functions-subnet"
  resource_group_name  = azurerm_resource_group.main.name
  virtual_network_name = azurerm_virtual_network.main.name
  address_prefixes     = ["10.0.2.0/24"]
  
  delegation {
    name = "functions-delegation"
    service_delegation {
      name = "Microsoft.Web/serverFarms"
      actions = [
        "Microsoft.Network/virtualNetworks/subnets/action"
      ]
    }
  }
}

resource "azurerm_network_security_group" "vmss" {
  name                = "${var.project_name}-vmss-nsg"
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  
  security_rule {
    name                       = "Allow-HTTPS"
    priority                   = 100
    direction                  = "Inbound"
    access                     = "Allow"
    protocol                   = "Tcp"
    source_port_range          = "*"
    destination_port_ranges    = ["443", "8080"]
    source_address_prefix      = "VirtualNetwork"
    destination_address_prefix = "*"
  }
  
  security_rule {
    name                       = "Allow-Health"
    priority                   = 110
    direction                  = "Inbound"
    access                     = "Allow"
    protocol                   = "Tcp"
    source_port_range          = "*"
    destination_port_range     = "8081"
    source_address_prefix      = "AzureLoadBalancer"
    destination_address_prefix = "*"
  }
  
  security_rule {
    name                       = "Deny-All-Inbound"
    priority                   = 4096
    direction                  = "Inbound"
    access                     = "Deny"
    protocol                   = "*"
    source_port_range          = "*"
    destination_port_range     = "*"
    source_address_prefix      = "*"
    destination_address_prefix = "*"
  }
  
  tags = local.tags
}

resource "azurerm_subnet_network_security_group_association" "vmss" {
  subnet_id                 = azurerm_subnet.vmss.id
  network_security_group_id = azurerm_network_security_group.vmss.id
}
HEREDOC

cat > terraform/functions.tf << 'HEREDOC'
# =============================================================================
# FUNCTION APP
# =============================================================================

resource "azurerm_service_plan" "functions" {
  name                = "${var.project_name}-func-plan"
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  os_type             = "Linux"
  sku_name            = "Y1"  # Consumption plan
  
  tags = local.tags
}

resource "azurerm_linux_function_app" "main" {
  name                = local.function_app_name
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  service_plan_id     = azurerm_service_plan.functions.id
  
  storage_account_name       = azurerm_storage_account.functions.name
  storage_account_access_key = azurerm_storage_account.functions.primary_access_key
  
  identity {
    type = "SystemAssigned"
  }
  
  site_config {
    application_stack {
      python_version = "3.11"
    }
    
    cors {
      allowed_origins = ["*"]
    }
    
    health_check_path                 = "/health/live"
    health_check_eviction_time_in_min = 5
  }
  
  app_settings = {
    "FUNCTIONS_WORKER_RUNTIME"       = "python"
    "PYTHON_ENABLE_WORKER_EXTENSIONS" = "1"
    "KEY_VAULT_NAME"                 = azurerm_key_vault.main.name
    "COSMOS_ACCOUNT"                 = azurerm_cosmosdb_account.main.name
    "PROJECT_NAME"                   = var.project_name
    "APPINSIGHTS_INSTRUMENTATIONKEY" = "@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.appinsights_key.id})"
    "COSMOS_DB_KEY"                  = "@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.cosmos_key.id})"
    "INFERENCE_API_KEY"              = "@Microsoft.KeyVault(SecretUri=${azurerm_key_vault_secret.inference_api_key.id})"
  }
  
  tags = local.tags
}

# Grant Function App access to Key Vault
resource "azurerm_role_assignment" "func_kv_secrets" {
  scope                = azurerm_key_vault.main.id
  role_definition_name = "Key Vault Secrets User"
  principal_id         = azurerm_linux_function_app.main.identity[0].principal_id
}

# Grant Function App access to Cosmos DB
resource "azurerm_cosmosdb_sql_role_assignment" "func_cosmos" {
  resource_group_name = azurerm_resource_group.main.name
  account_name        = azurerm_cosmosdb_account.main.name
  role_definition_id  = "${azurerm_cosmosdb_account.main.id}/sqlRoleDefinitions/00000000-0000-0000-0000-000000000002"
  principal_id        = azurerm_linux_function_app.main.identity[0].principal_id
  scope               = azurerm_cosmosdb_account.main.id
}
HEREDOC

cat > terraform/vmss.tf << 'HEREDOC'
# =============================================================================
# VM SCALE SET (GPU Spot Instances)
# =============================================================================

# Cloud-init script
locals {
  cloud_init_script = <<-EOF
    #!/bin/bash
    set -e
    
    # Install Docker
    apt-get update
    apt-get install -y docker.io curl jq
    
    # Install NVIDIA drivers and container toolkit
    curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
    curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
        tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
    
    apt-get update
    apt-get install -y nvidia-container-toolkit
    
    # Configure Docker with NVIDIA runtime
    nvidia-ctk runtime configure --runtime=docker
    systemctl restart docker
    
    # Pull inference server images
    docker pull ghcr.io/ggerganov/llama.cpp:server-cuda
    
    # Start health check server
    cat > /opt/health.py << 'HEALTH'
    from http.server import HTTPServer, BaseHTTPRequestHandler
    import json, subprocess
    
    class Handler(BaseHTTPRequestHandler):
        def do_GET(self):
            if self.path == '/health/ready':
                result = subprocess.run(['docker', 'ps', '-q'], capture_output=True)
                status = 200 if result.stdout else 503
            else:
                status = 200
            self.send_response(status)
            self.send_header('Content-Type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps({"status": "ok"}).encode())
    
    HTTPServer(('0.0.0.0', 8081), Handler).serve_forever()
    HEALTH
    
    nohup python3 /opt/health.py &
    
    echo "Initialization complete"
  EOF
}

resource "azurerm_linux_virtual_machine_scale_set" "gpu" {
  name                = local.vmss_name
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  sku                 = var.vmss_sku
  instances           = 0
  admin_username      = "azureuser"
  
  priority        = "Spot"
  max_bid_price   = var.vmss_spot_max_price
  eviction_policy = "Deallocate"
  
  upgrade_mode = "Automatic"
  
  identity {
    type = "SystemAssigned"
  }
  
  admin_ssh_key {
    username   = "azureuser"
    public_key = file("~/.ssh/id_rsa.pub")
  }
  
  source_image_reference {
    publisher = "Canonical"
    offer     = "0001-com-ubuntu-server-jammy"
    sku       = "22_04-lts-gen2"
    version   = "latest"
  }
  
  os_disk {
    storage_account_type = "StandardSSD_LRS"
    caching              = "ReadOnly"
    
    diff_disk_settings {
      option    = "Local"
      placement = "CacheDisk"
    }
  }
  
  network_interface {
    name    = "vmss-nic"
    primary = true
    
    ip_configuration {
      name      = "internal"
      primary   = true
      subnet_id = azurerm_subnet.vmss.id
    }
  }
  
  custom_data = base64encode(local.cloud_init_script)
  
  automatic_instance_repair {
    enabled      = true
    grace_period = "PT10M"
  }
  
  health_probe_id = azurerm_lb_probe.health.id
  
  extension {
    name                 = "HealthExtension"
    publisher            = "Microsoft.ManagedServices"
    type                 = "ApplicationHealthLinux"
    type_handler_version = "1.0"
    
    settings = jsonencode({
      protocol    = "http"
      port        = 8081
      requestPath = "/health/ready"
    })
  }
  
  tags = local.tags
  
  depends_on = [azurerm_lb.main]
}

# Internal Load Balancer for VMSS
resource "azurerm_lb" "main" {
  name                = "${var.project_name}-lb"
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  sku                 = "Standard"
  
  frontend_ip_configuration {
    name                          = "internal"
    subnet_id                     = azurerm_subnet.vmss.id
    private_ip_address_allocation = "Dynamic"
  }
  
  tags = local.tags
}

resource "azurerm_lb_backend_address_pool" "main" {
  name            = "vmss-backend"
  loadbalancer_id = azurerm_lb.main.id
}

resource "azurerm_lb_probe" "health" {
  name                = "health-probe"
  loadbalancer_id     = azurerm_lb.main.id
  protocol            = "Http"
  port                = 8081
  request_path        = "/health/ready"
  interval_in_seconds = 15
}

resource "azurerm_lb_rule" "inference" {
  name                           = "inference"
  loadbalancer_id                = azurerm_lb.main.id
  protocol                       = "Tcp"
  frontend_port                  = 8080
  backend_port                   = 8080
  frontend_ip_configuration_name = "internal"
  backend_address_pool_ids       = [azurerm_lb_backend_address_pool.main.id]
  probe_id                       = azurerm_lb_probe.health.id
}

# Grant VMSS access to Key Vault
resource "azurerm_role_assignment" "vmss_kv_secrets" {
  scope                = azurerm_key_vault.main.id
  role_definition_name = "Key Vault Secrets User"
  principal_id         = azurerm_linux_virtual_machine_scale_set.gpu.identity[0].principal_id
}

# Autoscaling
resource "azurerm_monitor_autoscale_setting" "vmss" {
  name                = "${local.vmss_name}-autoscale"
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  target_resource_id  = azurerm_linux_virtual_machine_scale_set.gpu.id
  
  profile {
    name = "default"
    
    capacity {
      default = 0
      minimum = var.vmss_min_instances
      maximum = var.vmss_max_instances
    }
    
    # Scale out on high CPU
    rule {
      metric_trigger {
        metric_name        = "Percentage CPU"
        metric_resource_id = azurerm_linux_virtual_machine_scale_set.gpu.id
        time_grain         = "PT1M"
        statistic          = "Average"
        time_window        = "PT5M"
        time_aggregation   = "Average"
        operator           = "GreaterThan"
        threshold          = 70
      }
      
      scale_action {
        direction = "Increase"
        type      = "ChangeCount"
        value     = "2"
        cooldown  = "PT5M"
      }
    }
    
    # Scale in on low CPU
    rule {
      metric_trigger {
        metric_name        = "Percentage CPU"
        metric_resource_id = azurerm_linux_virtual_machine_scale_set.gpu.id
        time_grain         = "PT1M"
        statistic          = "Average"
        time_window        = "PT10M"
        time_aggregation   = "Average"
        operator           = "LessThan"
        threshold          = 20
      }
      
      scale_action {
        direction = "Decrease"
        type      = "ChangeCount"
        value     = "1"
        cooldown  = "PT10M"
      }
    }
  }
  
  tags = local.tags
}
HEREDOC

cat > terraform/apim.tf << 'HEREDOC'
# =============================================================================
# API MANAGEMENT
# =============================================================================

resource "azurerm_api_management" "main" {
  name                = local.apim_name
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  publisher_name      = var.project_name
  publisher_email     = var.admin_email
  sku_name            = "Consumption_0"
  
  identity {
    type = "SystemAssigned"
  }
  
  tags = local.tags
}

# Grant APIM access to Key Vault
resource "azurerm_role_assignment" "apim_kv_secrets" {
  scope                = azurerm_key_vault.main.id
  role_definition_name = "Key Vault Secrets User"
  principal_id         = azurerm_api_management.main.identity[0].principal_id
}

# API Definition
resource "azurerm_api_management_api" "inference" {
  name                  = "inference-api"
  resource_group_name   = azurerm_resource_group.main.name
  api_management_name   = azurerm_api_management.main.name
  revision              = "1"
  display_name          = "AI Inference API"
  path                  = "v1"
  protocols             = ["https"]
  service_url           = "https://${azurerm_linux_function_app.main.default_hostname}"
  subscription_required = true
  
  import {
    content_format = "openapi+json"
    content_value  = file("${path.module}/../openapi.json")
  }
}

# Rate limiting policy
resource "azurerm_api_management_api_policy" "inference" {
  api_name            = azurerm_api_management_api.inference.name
  api_management_name = azurerm_api_management.main.name
  resource_group_name = azurerm_resource_group.main.name
  
  xml_content = <<XML
<policies>
  <inbound>
    <base />
    <rate-limit-by-key calls="60" renewal-period="60" counter-key="@(context.Subscription.Id)" />
    <set-header name="X-Forwarded-Host" exists-action="override">
      <value>@(context.Request.OriginalUrl.Host)</value>
    </set-header>
  </inbound>
  <backend>
    <base />
  </backend>
  <outbound>
    <base />
    <set-header name="X-Powered-By" exists-action="delete" />
  </outbound>
  <on-error>
    <base />
  </on-error>
</policies>
XML
}

# Health check API (no auth required)
resource "azurerm_api_management_api" "health" {
  name                  = "health-api"
  resource_group_name   = azurerm_resource_group.main.name
  api_management_name   = azurerm_api_management.main.name
  revision              = "1"
  display_name          = "Health API"
  path                  = "health"
  protocols             = ["https"]
  service_url           = "https://${azurerm_linux_function_app.main.default_hostname}/health"
  subscription_required = false
}

resource "azurerm_api_management_api_operation" "health_live" {
  operation_id        = "health-live"
  api_name            = azurerm_api_management_api.health.name
  api_management_name = azurerm_api_management.main.name
  resource_group_name = azurerm_resource_group.main.name
  display_name        = "Liveness Check"
  method              = "GET"
  url_template        = "/live"
}

resource "azurerm_api_management_api_operation" "health_ready" {
  operation_id        = "health-ready"
  api_name            = azurerm_api_management_api.health.name
  api_management_name = azurerm_api_management.main.name
  resource_group_name = azurerm_resource_group.main.name
  display_name        = "Readiness Check"
  method              = "GET"
  url_template        = "/ready"
}
HEREDOC

cat > terraform/outputs.tf << 'HEREDOC'
# =============================================================================
# OUTPUTS
# =============================================================================

output "resource_group_name" {
  description = "Resource group name"
  value       = azurerm_resource_group.main.name
}

output "key_vault_name" {
  description = "Key Vault name"
  value       = azurerm_key_vault.main.name
}

output "key_vault_uri" {
  description = "Key Vault URI"
  value       = azurerm_key_vault.main.vault_uri
}

output "function_app_name" {
  description = "Function App name"
  value       = azurerm_linux_function_app.main.name
}

output "function_app_url" {
  description = "Function App URL"
  value       = "https://${azurerm_linux_function_app.main.default_hostname}"
}

output "apim_gateway_url" {
  description = "API Management gateway URL"
  value       = azurerm_api_management.main.gateway_url
}

output "apim_developer_portal_url" {
  description = "API Management developer portal URL"
  value       = azurerm_api_management.main.developer_portal_url
}

output "cosmos_endpoint" {
  description = "Cosmos DB endpoint"
  value       = azurerm_cosmosdb_account.main.endpoint
}

output "vmss_name" {
  description = "VMSS name"
  value       = azurerm_linux_virtual_machine_scale_set.gpu.name
}

output "app_insights_instrumentation_key" {
  description = "Application Insights instrumentation key"
  value       = azurerm_application_insights.main.instrumentation_key
  sensitive   = true
}

output "deployment_summary" {
  description = "Deployment summary"
  value = <<-EOF
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    DEPLOYMENT COMPLETE
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Resource Group:    ${azurerm_resource_group.main.name}
    Location:          ${azurerm_resource_group.main.location}
    
    API Endpoints:
      Gateway:         ${azurerm_api_management.main.gateway_url}/v1
      Health:          ${azurerm_api_management.main.gateway_url}/health/live
      Dev Portal:      ${azurerm_api_management.main.developer_portal_url}
    
    Function App:      https://${azurerm_linux_function_app.main.default_hostname}
    Key Vault:         ${azurerm_key_vault.main.vault_uri}
    
    Next Steps:
      1. Deploy function code: func azure functionapp publish ${azurerm_linux_function_app.main.name}
      2. Get API key from Key Vault: az keyvault secret show --vault-name ${azurerm_key_vault.main.name} --name inference-api-key
      3. Test health: curl ${azurerm_api_management.main.gateway_url}/health/live
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  EOF
}
HEREDOC

cat > terraform/terraform.tfvars.example << 'HEREDOC'
# Copy this file to terraform.tfvars and customize

project_name = "ai-inference"
environment  = "prod"
location     = "eastus"

# GPU instance configuration
vmss_sku            = "Standard_NC4as_T4_v3"
vmss_spot_max_price = 0.15
vmss_min_instances  = 0
vmss_max_instances  = 20

# Admin configuration
admin_email = "admin@example.com"

# Optional features
enable_ddos_protection = false
HEREDOC

# =============================================================================
# 6. BICEP CONFIGURATION
# =============================================================================

cat > bicep/main.bicep << 'HEREDOC'
// =============================================================================
// AI Inference Arbitrage Platform - Bicep Configuration
// =============================================================================

targetScope = 'subscription'

@description('Project name used for resource naming')
@minLength(3)
@maxLength(20)
param projectName string = 'ai-inference'

@description('Environment')
@allowed(['dev', 'staging', 'prod'])
param environment string = 'prod'

@description('Azure region')
param location string = 'eastus'

@description('Admin email for notifications')
param adminEmail string = 'admin@example.com'

@description('VM SKU for GPU instances')
param vmSku string = 'Standard_NC4as_T4_v3'

@description('Maximum spot instance price')
param spotMaxPrice string = '0.15'

// Generate unique suffix
var uniqueSuffix = uniqueString(subscription().subscriptionId, projectName)
var shortSuffix = substring(uniqueSuffix, 0, 6)

var resourceGroupName = '${projectName}-${environment}-rg'

var tags = {
  project: projectName
  environment: environment
  managedBy: 'bicep'
}

// Resource Group
resource rg 'Microsoft.Resources/resourceGroups@2023-07-01' = {
  name: resourceGroupName
  location: location
  tags: tags
}

// Deploy all resources
module resources 'modules/resources.bicep' = {
  scope: rg
  name: 'resources-deployment'
  params: {
    projectName: projectName
    location: location
    suffix: shortSuffix
    tags: tags
    adminEmail: adminEmail
    vmSku: vmSku
    spotMaxPrice: spotMaxPrice
  }
}

// Outputs
output resourceGroupName string = rg.name
output keyVaultName string = resources.outputs.keyVaultName
output functionAppUrl string = resources.outputs.functionAppUrl
output apimGatewayUrl string = resources.outputs.apimGatewayUrl
HEREDOC

mkdir -p bicep/modules

cat > bicep/modules/resources.bicep << 'HEREDOC'
// =============================================================================
// Main Resources Module
// =============================================================================

param projectName string
param location string
param suffix string
param tags object
param adminEmail string
param vmSku string
param spotMaxPrice string

// Key Vault
module keyVault 'keyvault.bicep' = {
  name: 'keyvault-deployment'
  params: {
    name: '${projectName}-kv-${suffix}'
    location: location
    tags: tags
  }
}

// Monitoring
module monitoring 'monitoring.bicep' = {
  name: 'monitoring-deployment'
  params: {
    projectName: projectName
    location: location
    tags: tags
  }
}

// Storage
resource storageAccount 'Microsoft.Storage/storageAccounts@2023-01-01' = {
  name: '${replace(projectName, '-', '')}st${suffix}'
  location: location
  tags: tags
  sku: {
    name: 'Standard_LRS'
  }
  kind: 'StorageV2'
  properties: {
    minimumTlsVersion: 'TLS1_2'
    supportsHttpsTrafficOnly: true
  }
}

// Cosmos DB
module cosmos 'cosmos.bicep' = {
  name: 'cosmos-deployment'
  params: {
    name: '${projectName}-cosmos-${suffix}'
    location: location
    tags: tags
    keyVaultName: keyVault.outputs.name
  }
}

// Virtual Network
module network 'network.bicep' = {
  name: 'network-deployment'
  params: {
    projectName: projectName
    location: location
    tags: tags
  }
}

// Function App
module functionApp 'functions.bicep' = {
  name: 'functionapp-deployment'
  params: {
    name: '${projectName}-func-${suffix}'
    location: location
    tags: tags
    storageAccountName: storageAccount.name
    appInsightsName: monitoring.outputs.appInsightsName
    keyVaultName: keyVault.outputs.name
    cosmosAccountName: cosmos.outputs.accountName
  }
}

// VMSS
module vmss 'vmss.bicep' = {
  name: 'vmss-deployment'
  params: {
    name: '${projectName}-gpu'
    location: location
    tags: tags
    subnetId: network.outputs.vmssSubnetId
    vmSku: vmSku
    spotMaxPrice: spotMaxPrice
    keyVaultName: keyVault.outputs.name
  }
}

// API Management
module apim 'apim.bicep' = {
  name: 'apim-deployment'
  params: {
    name: '${projectName}-apim'
    location: location
    tags: tags
    publisherEmail: adminEmail
    publisherName: projectName
    functionAppHostname: functionApp.outputs.hostname
    keyVaultName: keyVault.outputs.name
  }
}

// Outputs
output keyVaultName string = keyVault.outputs.name
output functionAppUrl string = 'https://${functionApp.outputs.hostname}'
output apimGatewayUrl string = apim.outputs.gatewayUrl
HEREDOC

cat > bicep/modules/keyvault.bicep << 'HEREDOC'
// Key Vault Module

param name string
param location string
param tags object

resource keyVault 'Microsoft.KeyVault/vaults@2023-07-01' = {
  name: name
  location: location
  tags: tags
  properties: {
    tenantId: subscription().tenantId
    sku: {
      family: 'A'
      name: 'standard'
    }
    enableRbacAuthorization: true
    enableSoftDelete: true
    softDeleteRetentionInDays: 7
    enabledForDeployment: true
    enabledForTemplateDeployment: true
  }
}

// Generate API key
resource apiKeySecret 'Microsoft.KeyVault/vaults/secrets@2023-07-01' = {
  parent: keyVault
  name: 'inference-api-key'
  properties: {
    value: guid(keyVault.id, 'api-key')
  }
}

// Generate internal service key
resource internalKeySecret 'Microsoft.KeyVault/vaults/secrets@2023-07-01' = {
  parent: keyVault
  name: 'internal-service-key'
  properties: {
    value: guid(keyVault.id, 'internal-key')
  }
}

output name string = keyVault.name
output id string = keyVault.id
output uri string = keyVault.properties.vaultUri
HEREDOC

cat > bicep/modules/monitoring.bicep << 'HEREDOC'
// Monitoring Module (Log Analytics + App Insights)

param projectName string
param location string
param tags object

resource logAnalytics 'Microsoft.OperationalInsights/workspaces@2022-10-01' = {
  name: '${projectName}-logs'
  location: location
  tags: tags
  properties: {
    sku: {
      name: 'PerGB2018'
    }
    retentionInDays: 30
  }
}

resource appInsights 'Microsoft.Insights/components@2020-02-02' = {
  name: '${projectName}-insights'
  location: location
  tags: tags
  kind: 'web'
  properties: {
    Application_Type: 'web'
    WorkspaceResourceId: logAnalytics.id
  }
}

output logAnalyticsId string = logAnalytics.id
output appInsightsName string = appInsights.name
output appInsightsKey string = appInsights.properties.InstrumentationKey
output appInsightsConnectionString string = appInsights.properties.ConnectionString
HEREDOC

cat > bicep/modules/cosmos.bicep << 'HEREDOC'
// Cosmos DB Module (Serverless)

param name string
param location string
param tags object
param keyVaultName string

resource cosmosAccount 'Microsoft.DocumentDB/databaseAccounts@2023-11-15' = {
  name: name
  location: location
  tags: tags
  properties: {
    databaseAccountOfferType: 'Standard'
    capabilities: [
      {
        name: 'EnableServerless'
      }
    ]
    consistencyPolicy: {
      defaultConsistencyLevel: 'Eventual'
    }
    locations: [
      {
        locationName: location
        failoverPriority: 0
      }
    ]
  }
}

resource database 'Microsoft.DocumentDB/databaseAccounts/sqlDatabases@2023-11-15' = {
  parent: cosmosAccount
  name: 'inferencecache'
  properties: {
    resource: {
      id: 'inferencecache'
    }
  }
}

resource container 'Microsoft.DocumentDB/databaseAccounts/sqlDatabases/containers@2023-11-15' = {
  parent: database
  name: 'responses'
  properties: {
    resource: {
      id: 'responses'
      partitionKey: {
        paths: ['/modelId']
        kind: 'Hash'
      }
      defaultTtl: 3600
    }
  }
}

// Store key in Key Vault
resource keyVault 'Microsoft.KeyVault/vaults@2023-07-01' existing = {
  name: keyVaultName
}

resource cosmosKeySecret 'Microsoft.KeyVault/vaults/secrets@2023-07-01' = {
  parent: keyVault
  name: 'cosmos-db-key'
  properties: {
    value: cosmosAccount.listKeys().primaryMasterKey
  }
}

output accountName string = cosmosAccount.name
output endpoint string = cosmosAccount.properties.documentEndpoint
HEREDOC

cat > bicep/modules/network.bicep << 'HEREDOC'
// Network Module

param projectName string
param location string
param tags object

resource vnet 'Microsoft.Network/virtualNetworks@2023-05-01' = {
  name: '${projectName}-vnet'
  location: location
  tags: tags
  properties: {
    addressSpace: {
      addressPrefixes: ['10.0.0.0/16']
    }
    subnets: [
      {
        name: 'vmss-subnet'
        properties: {
          addressPrefix: '10.0.1.0/24'
          networkSecurityGroup: {
            id: nsg.id
          }
        }
      }
      {
        name: 'functions-subnet'
        properties: {
          addressPrefix: '10.0.2.0/24'
          delegations: [
            {
              name: 'functions-delegation'
              properties: {
                serviceName: 'Microsoft.Web/serverFarms'
              }
            }
          ]
        }
      }
    ]
  }
}

resource nsg 'Microsoft.Network/networkSecurityGroups@2023-05-01' = {
  name: '${projectName}-nsg'
  location: location
  tags: tags
  properties: {
    securityRules: [
      {
        name: 'Allow-HTTPS'
        properties: {
          priority: 100
          direction: 'Inbound'
          access: 'Allow'
          protocol: 'Tcp'
          sourcePortRange: '*'
          destinationPortRanges: ['443', '8080']
          sourceAddressPrefix: 'VirtualNetwork'
          destinationAddressPrefix: '*'
        }
      }
      {
        name: 'Allow-Health'
        properties: {
          priority: 110
          direction: 'Inbound'
          access: 'Allow'
          protocol: 'Tcp'
          sourcePortRange: '*'
          destinationPortRange: '8081'
          sourceAddressPrefix: 'AzureLoadBalancer'
          destinationAddressPrefix: '*'
        }
      }
    ]
  }
}

output vnetId string = vnet.id
output vmssSubnetId string = vnet.properties.subnets[0].id
output functionsSubnetId string = vnet.properties.subnets[1].id
HEREDOC

cat > bicep/modules/functions.bicep << 'HEREDOC'
// Function App Module

param name string
param location string
param tags object
param storageAccountName string
param appInsightsName string
param keyVaultName string
param cosmosAccountName string

resource storageAccount 'Microsoft.Storage/storageAccounts@2023-01-01' existing = {
  name: storageAccountName
}

resource appInsights 'Microsoft.Insights/components@2020-02-02' existing = {
  name: appInsightsName
}

resource hostingPlan 'Microsoft.Web/serverfarms@2023-01-01' = {
  name: '${name}-plan'
  location: location
  tags: tags
  sku: {
    name: 'Y1'
    tier: 'Dynamic'
  }
  properties: {
    reserved: true
  }
}

resource functionApp 'Microsoft.Web/sites@2023-01-01' = {
  name: name
  location: location
  tags: tags
  kind: 'functionapp,linux'
  identity: {
    type: 'SystemAssigned'
  }
  properties: {
    serverFarmId: hostingPlan.id
    httpsOnly: true
    siteConfig: {
      linuxFxVersion: 'PYTHON|3.11'
      pythonVersion: '3.11'
      appSettings: [
        {
          name: 'AzureWebJobsStorage'
          value: 'DefaultEndpointsProtocol=https;AccountName=${storageAccount.name};EndpointSuffix=${environment().suffixes.storage};AccountKey=${storageAccount.listKeys().keys[0].value}'
        }
        {
          name: 'FUNCTIONS_WORKER_RUNTIME'
          value: 'python'
        }
        {
          name: 'FUNCTIONS_EXTENSION_VERSION'
          value: '~4'
        }
        {
          name: 'APPINSIGHTS_INSTRUMENTATIONKEY'
          value: appInsights.properties.InstrumentationKey
        }
        {
          name: 'KEY_VAULT_NAME'
          value: keyVaultName
        }
        {
          name: 'COSMOS_ACCOUNT'
          value: cosmosAccountName
        }
      ]
      healthCheckPath: '/health/live'
    }
  }
}

// Grant Key Vault access
resource keyVault 'Microsoft.KeyVault/vaults@2023-07-01' existing = {
  name: keyVaultName
}

resource kvRoleAssignment 'Microsoft.Authorization/roleAssignments@2022-04-01' = {
  name: guid(keyVault.id, functionApp.id, 'Key Vault Secrets User')
  scope: keyVault
  properties: {
    roleDefinitionId: subscriptionResourceId('Microsoft.Authorization/roleDefinitions', '4633458b-17de-408a-b874-0445c86b69e6')
    principalId: functionApp.identity.principalId
    principalType: 'ServicePrincipal'
  }
}

output name string = functionApp.name
output hostname string = functionApp.properties.defaultHostName
output principalId string = functionApp.identity.principalId
HEREDOC

cat > bicep/modules/vmss.bicep << 'HEREDOC'
// VMSS Module (GPU Spot Instances)

param name string
param location string
param tags object
param subnetId string
param vmSku string
param spotMaxPrice string
param keyVaultName string

var cloudInitScript = '''
#!/bin/bash
apt-get update && apt-get install -y docker.io
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | gpg --dearmor -o /usr/share/keyrings/nvidia.gpg
apt-get update && apt-get install -y nvidia-container-toolkit
nvidia-ctk runtime configure --runtime=docker && systemctl restart docker
docker pull ghcr.io/ggerganov/llama.cpp:server-cuda
'''

resource vmss 'Microsoft.Compute/virtualMachineScaleSets@2023-07-01' = {
  name: name
  location: location
  tags: tags
  sku: {
    name: vmSku
    tier: 'Standard'
    capacity: 0
  }
  identity: {
    type: 'SystemAssigned'
  }
  properties: {
    upgradePolicy: {
      mode: 'Automatic'
    }
    virtualMachineProfile: {
      priority: 'Spot'
      billingProfile: {
        maxPrice: json(spotMaxPrice)
      }
      evictionPolicy: 'Deallocate'
      osProfile: {
        computerNamePrefix: 'gpu'
        adminUsername: 'azureuser'
        customData: base64(cloudInitScript)
        linuxConfiguration: {
          disablePasswordAuthentication: true
          ssh: {
            publicKeys: [
              {
                path: '/home/azureuser/.ssh/authorized_keys'
                keyData: 'ssh-rsa PLACEHOLDER_KEY'
              }
            ]
          }
        }
      }
      storageProfile: {
        imageReference: {
          publisher: 'Canonical'
          offer: '0001-com-ubuntu-server-jammy'
          sku: '22_04-lts-gen2'
          version: 'latest'
        }
        osDisk: {
          createOption: 'FromImage'
          caching: 'ReadOnly'
          managedDisk: {
            storageAccountType: 'StandardSSD_LRS'
          }
          diffDiskSettings: {
            option: 'Local'
            placement: 'CacheDisk'
          }
        }
      }
      networkProfile: {
        networkInterfaceConfigurations: [
          {
            name: 'nic'
            properties: {
              primary: true
              ipConfigurations: [
                {
                  name: 'ipconfig'
                  properties: {
                    subnet: {
                      id: subnetId
                    }
                  }
                }
              ]
            }
          }
        ]
      }
      extensionProfile: {
        extensions: [
          {
            name: 'HealthExtension'
            properties: {
              publisher: 'Microsoft.ManagedServices'
              type: 'ApplicationHealthLinux'
              typeHandlerVersion: '1.0'
              autoUpgradeMinorVersion: true
              settings: {
                protocol: 'http'
                port: 8081
                requestPath: '/health/ready'
              }
            }
          }
        ]
      }
    }
    automaticRepairsPolicy: {
      enabled: true
      gracePeriod: 'PT10M'
    }
  }
}

// Autoscale
resource autoscale 'Microsoft.Insights/autoscalesettings@2022-10-01' = {
  name: '${name}-autoscale'
  location: location
  tags: tags
  properties: {
    targetResourceUri: vmss.id
    enabled: true
    profiles: [
      {
        name: 'default'
        capacity: {
          default: '0'
          minimum: '0'
          maximum: '20'
        }
        rules: [
          {
            metricTrigger: {
              metricName: 'Percentage CPU'
              metricResourceUri: vmss.id
              timeGrain: 'PT1M'
              statistic: 'Average'
              timeWindow: 'PT5M'
              timeAggregation: 'Average'
              operator: 'GreaterThan'
              threshold: 70
            }
            scaleAction: {
              direction: 'Increase'
              type: 'ChangeCount'
              value: '2'
              cooldown: 'PT5M'
            }
          }
          {
            metricTrigger: {
              metricName: 'Percentage CPU'
              metricResourceUri: vmss.id
              timeGrain: 'PT1M'
              statistic: 'Average'
              timeWindow: 'PT10M'
              timeAggregation: 'Average'
              operator: 'LessThan'
              threshold: 20
            }
            scaleAction: {
              direction: 'Decrease'
              type: 'ChangeCount'
              value: '1'
              cooldown: 'PT10M'
            }
          }
        ]
      }
    ]
  }
}

// Grant Key Vault access
resource keyVault 'Microsoft.KeyVault/vaults@2023-07-01' existing = {
  name: keyVaultName
}

resource kvRoleAssignment 'Microsoft.Authorization/roleAssignments@2022-04-01' = {
  name: guid(keyVault.id, vmss.id, 'Key Vault Secrets User')
  scope: keyVault
  properties: {
    roleDefinitionId: subscriptionResourceId('Microsoft.Authorization/roleDefinitions', '4633458b-17de-408a-b874-0445c86b69e6')
    principalId: vmss.identity.principalId
    principalType: 'ServicePrincipal'
  }
}

output name string = vmss.name
output principalId string = vmss.identity.principalId
HEREDOC

cat > bicep/modules/apim.bicep << 'HEREDOC'
// API Management Module

param name string
param location string
param tags object
param publisherEmail string
param publisherName string
param functionAppHostname string
param keyVaultName string

resource apim 'Microsoft.ApiManagement/service@2023-03-01-preview' = {
  name: name
  location: location
  tags: tags
  sku: {
    name: 'Consumption'
    capacity: 0
  }
  identity: {
    type: 'SystemAssigned'
  }
  properties: {
    publisherEmail: publisherEmail
    publisherName: publisherName
  }
}

// Inference API
resource inferenceApi 'Microsoft.ApiManagement/service/apis@2023-03-01-preview' = {
  parent: apim
  name: 'inference-api'
  properties: {
    displayName: 'AI Inference API'
    path: 'v1'
    protocols: ['https']
    serviceUrl: 'https://${functionAppHostname}'
    subscriptionRequired: true
  }
}

// Health API (no auth)
resource healthApi 'Microsoft.ApiManagement/service/apis@2023-03-01-preview' = {
  parent: apim
  name: 'health-api'
  properties: {
    displayName: 'Health API'
    path: 'health'
    protocols: ['https']
    serviceUrl: 'https://${functionAppHostname}/health'
    subscriptionRequired: false
  }
}

resource healthLiveOperation 'Microsoft.ApiManagement/service/apis/operations@2023-03-01-preview' = {
  parent: healthApi
  name: 'health-live'
  properties: {
    displayName: 'Liveness Check'
    method: 'GET'
    urlTemplate: '/live'
  }
}

resource healthReadyOperation 'Microsoft.ApiManagement/service/apis/operations@2023-03-01-preview' = {
  parent: healthApi
  name: 'health-ready'
  properties: {
    displayName: 'Readiness Check'
    method: 'GET'
    urlTemplate: '/ready'
  }
}

// Grant Key Vault access
resource keyVault 'Microsoft.KeyVault/vaults@2023-07-01' existing = {
  name: keyVaultName
}

resource kvRoleAssignment 'Microsoft.Authorization/roleAssignments@2022-04-01' = {
  name: guid(keyVault.id, apim.id, 'Key Vault Secrets User')
  scope: keyVault
  properties: {
    roleDefinitionId: subscriptionResourceId('Microsoft.Authorization/roleDefinitions', '4633458b-17de-408a-b874-0445c86b69e6')
    principalId: apim.identity.principalId
    principalType: 'ServicePrincipal'
  }
}

output name string = apim.name
output gatewayUrl string = apim.properties.gatewayUrl
HEREDOC

# =============================================================================
# 7. GITHUB ACTIONS CI/CD
# =============================================================================

cat > .github/workflows/ci.yml << 'HEREDOC'
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  PYTHON_VERSION: '3.11'

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r src/requirements.txt
          pip install pytest pytest-cov pytest-asyncio black flake8 mypy
      
      - name: Lint with flake8
        run: |
          flake8 src --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 src --count --exit-zero --max-complexity=10 --max-line-length=120 --statistics
      
      - name: Format check with black
        run: black --check src
      
      - name: Type check with mypy
        run: mypy src --ignore-missing-imports
        continue-on-error: true
      
      - name: Run tests
        run: pytest tests -v --cov=src --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          fail_ci_if_error: false

  validate-terraform:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
      
      - name: Terraform Format Check
        run: terraform fmt -check -recursive
        working-directory: terraform
      
      - name: Terraform Init
        run: terraform init -backend=false
        working-directory: terraform
      
      - name: Terraform Validate
        run: terraform validate
        working-directory: terraform

  validate-bicep:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Azure CLI Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
        continue-on-error: true
      
      - name: Validate Bicep
        run: |
          az bicep build --file bicep/main.bicep --stdout > /dev/null
        continue-on-error: true
HEREDOC

cat > .github/workflows/deploy-functions.yml << 'HEREDOC'
name: Deploy Function App

on:
  push:
    branches: [main]
    paths:
      - 'src/**'
      - '.github/workflows/deploy-functions.yml'
  workflow
Claude Opus 4.5
continue


Thought Process
expand
bash
# Continuing from .github/workflows/deploy-functions.yml...

cat > .github/workflows/deploy-functions.yml << 'HEREDOC'
name: Deploy Function App

on:
  push:
    branches: [main]
    paths:
      - 'src/**'
      - '.github/workflows/deploy-functions.yml'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'prod'
        type: choice
        options:
          - dev
          - staging
          - prod

env:
  PYTHON_VERSION: '3.11'
  AZURE_FUNCTIONAPP_NAME: ${{ vars.FUNCTION_APP_NAME }}

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r src/requirements.txt
      
      - name: Run tests
        run: pytest tests -v --tb=short
        continue-on-error: true
      
      - name: Prepare deployment package
        run: |
          cd src
          zip -r ../deployment.zip . -x "*.pyc" -x "__pycache__/*" -x ".pytest_cache/*"
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: function-app
          path: deployment.zip
          retention-days: 5

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'prod' }}
    
    steps:
      - name: Download artifact
        uses: actions/download-artifact@v4
        with:
          name: function-app
      
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      
      - name: Deploy to Azure Functions
        uses: azure/functions-action@v1
        with:
          app-name: ${{ env.AZURE_FUNCTIONAPP_NAME }}
          package: deployment.zip
          publish-profile: ${{ secrets.AZURE_FUNCTIONAPP_PUBLISH_PROFILE }}
      
      - name: Health Check
        run: |
          echo "Waiting for deployment to complete..."
          sleep 30
          
          HEALTH_URL="https://${{ env.AZURE_FUNCTIONAPP_NAME }}.azurewebsites.net/health/ready"
          
          for i in {1..10}; do
            STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$HEALTH_URL")
            if [ "$STATUS" = "200" ]; then
              echo "âœ… Health check passed"
              exit 0
            fi
            echo "Attempt $i: Status $STATUS, retrying..."
            sleep 10
          done
          
          echo "âŒ Health check failed"
          exit 1
      
      - name: Notify on failure
        if: failure()
        run: |
          echo "::error::Deployment failed or health check did not pass"
HEREDOC

cat > .github/workflows/deploy-infrastructure.yml << 'HEREDOC'
name: Deploy Infrastructure

on:
  push:
    branches: [main]
    paths:
      - 'terraform/**'
      - 'bicep/**'
      - '.github/workflows/deploy-infrastructure.yml'
  workflow_dispatch:
    inputs:
      iac_tool:
        description: 'Infrastructure as Code tool'
        required: true
        default: 'terraform'
        type: choice
        options:
          - terraform
          - bicep
      action:
        description: 'Action to perform'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - apply
          - destroy
      environment:
        description: 'Target environment'
        required: true
        default: 'prod'
        type: choice
        options:
          - dev
          - staging
          - prod

env:
  ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
  ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
  ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
  ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
  TF_VAR_environment: ${{ github.event.inputs.environment || 'prod' }}

jobs:
  terraform:
    if: github.event.inputs.iac_tool == 'terraform' || github.event.inputs.iac_tool == ''
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'prod' }}
    defaults:
      run:
        working-directory: terraform
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
      
      - name: Terraform Init
        run: |
          terraform init \
            -backend-config="storage_account_name=${{ secrets.TF_STATE_STORAGE_ACCOUNT }}" \
            -backend-config="container_name=tfstate" \
            -backend-config="key=${{ env.TF_VAR_environment }}.tfstate" \
            -backend-config="resource_group_name=${{ secrets.TF_STATE_RESOURCE_GROUP }}"
      
      - name: Terraform Format
        run: terraform fmt -check
      
      - name: Terraform Validate
        run: terraform validate
      
      - name: Terraform Plan
        id: plan
        run: |
          terraform plan \
            -var-file="environments/${{ env.TF_VAR_environment }}.tfvars" \
            -out=tfplan \
            -no-color
        continue-on-error: true
      
      - name: Upload Plan
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan
          path: terraform/tfplan
          retention-days: 5
      
      - name: Terraform Plan Status
        if: steps.plan.outcome == 'failure'
        run: exit 1
      
      - name: Terraform Apply
        if: github.event.inputs.action == 'apply' && github.ref == 'refs/heads/main'
        run: terraform apply -auto-approve tfplan
      
      - name: Terraform Destroy
        if: github.event.inputs.action == 'destroy'
        run: |
          terraform destroy \
            -var-file="environments/${{ env.TF_VAR_environment }}.tfvars" \
            -auto-approve

  bicep:
    if: github.event.inputs.iac_tool == 'bicep'
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'prod' }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      
      - name: Validate Bicep
        run: az bicep build --file bicep/main.bicep
      
      - name: What-If (Preview Changes)
        if: github.event.inputs.action == 'plan' || github.event.inputs.action == ''
        run: |
          az deployment sub what-if \
            --location eastus \
            --template-file bicep/main.bicep \
            --parameters environment=${{ env.TF_VAR_environment }}
      
      - name: Deploy Bicep
        if: github.event.inputs.action == 'apply' && github.ref == 'refs/heads/main'
        run: |
          az deployment sub create \
            --location eastus \
            --template-file bicep/main.bicep \
            --parameters environment=${{ env.TF_VAR_environment }} \
            --name "deploy-${{ github.run_number }}"
      
      - name: Delete Resources
        if: github.event.inputs.action == 'destroy'
        run: |
          RG_NAME="ai-inference-${{ env.TF_VAR_environment }}-rg"
          az group delete --name "$RG_NAME" --yes --no-wait
HEREDOC

cat > .github/workflows/security-scan.yml << 'HEREDOC'
name: Security Scan

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 6 * * 1'  # Weekly on Monday

jobs:
  dependency-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install safety
        run: pip install safety
      
      - name: Check for vulnerabilities
        run: safety check -r src/requirements.txt
        continue-on-error: true
      
      - name: Upload results
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: safety-report.sarif
        continue-on-error: true

  secrets-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: TruffleHog Scan
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: ${{ github.event.repository.default_branch }}
          head: HEAD
          extra_args: --only-verified

  terraform-security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: tfsec
        uses: aquasecurity/tfsec-action@v1.0.0
        with:
          working_directory: terraform
          soft_fail: true
      
      - name: Checkov
        uses: bridgecrewio/checkov-action@v12
        with:
          directory: terraform
          framework: terraform
          soft_fail: true

  container-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Build test image
        run: |
          cat > Dockerfile.test << 'EOF'
          FROM python:3.11-slim
          COPY src/requirements.txt .
          RUN pip install -r requirements.txt
          EOF
          docker build -f Dockerfile.test -t test-image .
      
      - name: Trivy scan
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'test-image'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
      
      - name: Upload Trivy results
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'
HEREDOC

cat > .github/workflows/health-monitor.yml << 'HEREDOC'
name: Health Monitor

on:
  schedule:
    - cron: '*/15 * * * *'  # Every 15 minutes
  workflow_dispatch:

env:
  APIM_URL: ${{ vars.APIM_GATEWAY_URL }}

jobs:
  health-check:
    runs-on: ubuntu-latest
    steps:
      - name: Check API Health
        id: health
        run: |
          LIVE_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "${{ env.APIM_URL }}/health/live" || echo "000")
          READY_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "${{ env.APIM_URL }}/health/ready" || echo "000")
          
          echo "live_status=$LIVE_STATUS" >> $GITHUB_OUTPUT
          echo "ready_status=$READY_STATUS" >> $GITHUB_OUTPUT
          
          echo "Liveness: $LIVE_STATUS"
          echo "Readiness: $READY_STATUS"
          
          if [ "$LIVE_STATUS" != "200" ]; then
            echo "::error::Liveness check failed with status $LIVE_STATUS"
            exit 1
          fi
      
      - name: Check API Latency
        run: |
          START=$(date +%s%N)
          curl -s "${{ env.APIM_URL }}/health/live" > /dev/null
          END=$(date +%s%N)
          LATENCY=$(( ($END - $START) / 1000000 ))
          
          echo "Latency: ${LATENCY}ms"
          
          if [ "$LATENCY" -gt 5000 ]; then
            echo "::warning::High latency detected: ${LATENCY}ms"
          fi
      
      - name: Create Issue on Failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const title = `ðŸš¨ Health Check Failed - ${new Date().toISOString()}`;
            const body = `
            ## Health Check Failure
            
            - **Live Status**: ${{ steps.health.outputs.live_status }}
            - **Ready Status**: ${{ steps.health.outputs.ready_status }}
            - **Time**: ${new Date().toISOString()}
            - **Run**: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
            
            Please investigate immediately.
            `;
            
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['incident', 'automated']
            });
HEREDOC

# =============================================================================
# 8. TESTS
# =============================================================================

cat > tests/__init__.py << 'HEREDOC'
"""Test suite for AI Inference Platform."""
HEREDOC

cat > tests/conftest.py << 'HEREDOC'
"""Pytest configuration and fixtures."""

import os
import sys
import pytest

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

@pytest.fixture
def mock_env(monkeypatch):
    """Set up mock environment variables."""
    monkeypatch.setenv("KEY_VAULT_NAME", "test-keyvault")
    monkeypatch.setenv("COSMOS_ACCOUNT", "test-cosmos")
    monkeypatch.setenv("PROJECT_NAME", "test-project")
    monkeypatch.setenv("AZURE_SUBSCRIPTION_ID", "00000000-0000-0000-0000-000000000000")

@pytest.fixture
def sample_chat_request():
    """Sample chat completion request."""
    return {
        "model": "mixtral-8x7b",
        "messages": [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Hello, how are you?"}
        ],
        "max_tokens": 256,
        "temperature": 0.7
    }

@pytest.fixture
def sample_chat_response():
    """Sample chat completion response."""
    return {
        "id": "chatcmpl-test123",
        "object": "chat.completion",
        "created": 1699500000,
        "model": "mixtral-8x7b",
        "choices": [
            {
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": "Hello! I'm doing well, thank you for asking."
                },
                "finish_reason": "stop"
            }
        ],
        "usage": {
            "prompt_tokens": 20,
            "completion_tokens": 15,
            "total_tokens": 35
        }
    }
HEREDOC

cat > tests/test_health.py << 'HEREDOC'
"""Tests for health check endpoints."""

import json
import pytest
from unittest.mock import MagicMock, patch


class TestHealthEndpoints:
    """Test health check functionality."""
    
    def test_liveness_returns_200(self, mock_env):
        """Test that liveness probe returns 200."""
        from health.health_functions import main
        
        req = MagicMock()
        req.route_params = {"check_type": "live"}
        
        response = main(req)
        
        assert response.status_code == 200
        body = json.loads(response.get_body())
        assert body["status"] == "healthy"
        assert "timestamp" in body
    
    def test_readiness_checks_dependencies(self, mock_env):
        """Test that readiness probe checks dependencies."""
        from health.health_functions import main
        
        req = MagicMock()
        req.route_params = {"check_type": "ready"}
        
        with patch('health.health_functions.check_keyvault') as mock_kv:
            with patch('health.health_functions.check_cosmos') as mock_cosmos:
                with patch('health.health_functions.check_inference_backend') as mock_backend:
                    mock_kv.return_value = {"status": "healthy"}
                    mock_cosmos.return_value = {"status": "healthy"}
                    mock_backend.return_value = {"status": "healthy"}
                    
                    response = main(req)
        
        assert response.status_code == 200
        body = json.loads(response.get_body())
        assert "checks" in body
    
    def test_unknown_check_type_returns_400(self, mock_env):
        """Test that unknown check type returns 400."""
        from health.health_functions import main
        
        req = MagicMock()
        req.route_params = {"check_type": "unknown"}
        
        response = main(req)
        
        assert response.status_code == 400
    
    def test_startup_probe(self, mock_env):
        """Test startup probe."""
        from health.health_functions import main
        
        req = MagicMock()
        req.route_params = {"check_type": "startup"}
        
        response = main(req)
        
        assert response.status_code == 200
HEREDOC

cat > tests/test_api_orchestrator.py << 'HEREDOC'
"""Tests for API orchestrator."""

import json
import pytest
from unittest.mock import MagicMock, patch, AsyncMock


class TestModelRouter:
    """Test model routing logic."""
    
    def test_explicit_model_selection(self, mock_env):
        """Test that explicit model selection is respected."""
        from api_orchestrator.main import ModelRouter
        
        router = ModelRouter()
        messages = [{"role": "user", "content": "Hello"}]
        
        result = router.select_model("llama-3-70b", messages)
        
        assert result == "llama-3-70b"
    
    def test_auto_model_selection_short_prompt(self, mock_env):
        """Test auto model selection for short prompts."""
        from api_orchestrator.main import ModelRouter
        
        router = ModelRouter()
        messages = [{"role": "user", "content": "Hi"}]
        
        result = router.select_model("auto", messages)
        
        assert result == "phi-3-mini"  # Cheapest for short prompts
    
    def test_auto_model_selection_long_prompt(self, mock_env):
        """Test auto model selection for long prompts."""
        from api_orchestrator.main import ModelRouter
        
        router = ModelRouter()
        # Create a long message (>4000 tokens estimated)
        long_content = "word " * 5000
        messages = [{"role": "user", "content": long_content}]
        
        result = router.select_model("auto", messages)
        
        assert result == "mixtral-8x7b"  # Has longest context


class TestCacheManager:
    """Test caching functionality."""
    
    def test_cache_key_generation(self, mock_env, sample_chat_request):
        """Test that cache keys are deterministic."""
        from api_orchestrator.main import CacheManager
        
        cache = CacheManager()
        
        key1 = cache._generate_cache_key(sample_chat_request)
        key2 = cache._generate_cache_key(sample_chat_request)
        
        assert key1 == key2
        assert len(key1) == 32
    
    def test_different_requests_different_keys(self, mock_env, sample_chat_request):
        """Test that different requests produce different keys."""
        from api_orchestrator.main import CacheManager
        
        cache = CacheManager()
        
        request2 = sample_chat_request.copy()
        request2["temperature"] = 0.5
        
        key1 = cache._generate_cache_key(sample_chat_request)
        key2 = cache._generate_cache_key(request2)
        
        assert key1 != key2


class TestChatCompletions:
    """Test chat completions endpoint."""
    
    def test_missing_messages_returns_400(self, mock_env):
        """Test that missing messages field returns 400."""
        from api_orchestrator.main import main
        
        req = MagicMock()
        req.get_json.return_value = {"model": "mixtral-8x7b"}
        req.headers = {}
        
        response = main(req)
        
        assert response.status_code == 400
        body = json.loads(response.get_body())
        assert "error" in body
    
    def test_invalid_json_returns_400(self, mock_env):
        """Test that invalid JSON returns 400."""
        from api_orchestrator.main import main
        
        req = MagicMock()
        req.get_json.side_effect = ValueError("Invalid JSON")
        req.headers = {}
        
        response = main(req)
        
        assert response.status_code == 400
    
    def test_cache_hit_returns_cached_response(self, mock_env, sample_chat_request, sample_chat_response):
        """Test that cache hits return cached response."""
        from api_orchestrator.main import main, cache_manager
        
        req = MagicMock()
        req.get_json.return_value = sample_chat_request
        req.headers = {"X-Request-ID": "test-123"}
        
        with patch.object(cache_manager, 'get_cached_response', new_callable=AsyncMock) as mock_cache:
            mock_cache.return_value = sample_chat_response
            
            response = main(req)
        
        assert response.status_code == 200
        assert response.headers.get("X-Cache") == "HIT"
HEREDOC

cat > tests/test_integration.py << 'HEREDOC'
"""Integration tests (require Azure resources)."""

import os
import pytest
import requests

# Skip if no Azure credentials
pytestmark = pytest.mark.skipif(
    not os.environ.get("AZURE_SUBSCRIPTION_ID"),
    reason="Azure credentials not available"
)


class TestLiveEndpoints:
    """Test live Azure endpoints."""
    
    @pytest.fixture
    def api_url(self):
        return os.environ.get("API_URL", "https://ai-inference-apim.azure-api.net")
    
    @pytest.fixture
    def api_key(self):
        return os.environ.get("API_KEY")
    
    def test_health_live_endpoint(self, api_url):
        """Test liveness endpoint is accessible."""
        response = requests.get(f"{api_url}/health/live", timeout=10)
        assert response.status_code == 200
        assert response.json()["status"] == "healthy"
    
    def test_health_ready_endpoint(self, api_url):
        """Test readiness endpoint."""
        response = requests.get(f"{api_url}/health/ready", timeout=10)
        assert response.status_code in [200, 503]
    
    @pytest.mark.skipif(not os.environ.get("API_KEY"), reason="API_KEY not set")
    def test_chat_completions(self, api_url, api_key):
        """Test chat completions endpoint."""
        response = requests.post(
            f"{api_url}/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            json={
                "model": "phi-3-mini",
                "messages": [{"role": "user", "content": "Say hello"}],
                "max_tokens": 10
            },
            timeout=60
        )
        
        assert response.status_code == 200
        data = response.json()
        assert "choices" in data
        assert len(data["choices"]) > 0
HEREDOC

# =============================================================================
# 9. DOCUMENTATION
# =============================================================================

cat > docs/deployment-guide.md << 'HEREDOC'
# Deployment Guide

## Prerequisites

- Azure CLI >= 2.50.0
- Terraform >= 1.5.0 (for Terraform deployment)
- Azure subscription with GPU quota
- GitHub account (for CI/CD)

## Quick Start

### Option 1: Bash Script

```bash
# Clone and configure
git clone <repo-url>
cd ai-inference-platform

# Set configuration
export PROJECT_NAME="my-ai-platform"
export AZURE_LOCATION="eastus"

# Deploy
./deploy.sh
Option 2: Terraform
bash
cd terraform

# Initialize
terraform init

# Review plan
terraform plan -var="project_name=my-ai-platform"

# Deploy
terraform apply -var="project_name=my-ai-platform"
Option 3: Bicep
bash
# Deploy to subscription
az deployment sub create \
  --location eastus \
  --template-file bicep/main.bicep \
  --parameters projectName=my-ai-platform
Configuration
Environment Variables
Variable	Description	Required
PROJECT_NAME	Project identifier	Yes
AZURE_LOCATION	Azure region	No (default: eastus)
VMSS_SKU	GPU VM size	No (default: Standard_NC4as_T4_v3)
VMSS_SPOT_MAX_PRICE	Max spot price	No (default: 0.15)
Secrets (Stored in Key Vault)
inference-api-key: API key for clients
internal-service-key: Inter-service authentication
cosmos-db-key: Cosmos DB access key
appinsights-key: Application Insights key
Post-Deployment
1. Deploy Function Code
bash
cd src
func azure functionapp publish <function-app-name>
2. Verify Health
bash
curl https://<apim-name>.azure-api.net/health/live
curl https://<apim-name>.azure-api.net/health/ready
3. Get API Key
bash
az keyvault secret show \
  --vault-name <keyvault-name> \
  --name inference-api-key \
  --query value -o tsv
4. Test API
bash
curl -X POST https://<apim-name>.azure-api.net/v1/chat/completions \
  -H "Authorization: Bearer <api-key>" \
  -H "Content-Type: application/json" \
  -d '{"model":"phi-3-mini","messages":[{"role":"user","content":"Hello"}]}'
CI/CD Setup
GitHub Secrets
Configure these secrets in your GitHub repository:

Secret	Description
AZURE_CREDENTIALS	Service principal JSON
ARM_CLIENT_ID	Service principal client ID
ARM_CLIENT_SECRET	Service principal secret
ARM_SUBSCRIPTION_ID	Azure subscription ID
ARM_TENANT_ID	Azure AD tenant ID
AZURE_FUNCTIONAPP_PUBLISH_PROFILE	Function app publish profile
GitHub Variables
Variable	Description
FUNCTION_APP_NAME	Function app name
APIM_GATEWAY_URL	API Management gateway URL
Creating Service Principal
bash
az ad sp create-for-rbac \
  --name "github-actions-sp" \
  --role contributor \
  --scopes /subscriptions/<subscription-id> \
  --sdk-auth
Scaling
Manual Scaling
bash
# Scale VMSS
az vmss scale \
  --name <vmss-name> \
  --resource-group <rg-name> \
  --new-capacity 5
Autoscale Rules
Default rules:

Scale out +2 when CPU > 70% for 5 min
Scale in -1 when CPU < 20% for 10 min
Troubleshooting
Common Issues
Spot instance preemption: Instances auto-recover within 30s
GPU quota: Request quota increase in Azure portal
Health check failures: Check Application Insights logs
Useful Commands
bash
# View function logs
func azure functionapp logstream <function-app-name>

# View VMSS instances
az vmss list-instances -n <vmss-name> -g <rg-name>

# Check autoscale activity
az monitor autoscale show -n <vmss-name>-autoscale -g <rg-name>
HEREDOC

cat > docs/api-usage.md << 'HEREDOC'

API Usage Guide
Base URL
text
https://<apim-name>.azure-api.net/v1
Authentication
All API requests require a Bearer token:

bash
Authorization: Bearer YOUR_API_KEY
Endpoints
POST /chat/completions
Create a chat completion.

Request:

json
{
  "model": "mixtral-8x7b",
  "messages": [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"}
  ],
  "max_tokens": 256,
  "temperature": 0.7,
  "stream": false
}
Response:

json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1699500000,
  "model": "mixtral-8x7b",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I help you today?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 10,
    "total_tokens": 30
  }
}
GET /models
List available models.

Response:

json
{
  "object": "list",
  "data": [
    {
      "id": "mixtral-8x7b",
      "object": "model",
      "context_length": 32768,
      "pricing": {"prompt": 0.002, "completion": 0.002}
    }
  ]
}
GET /health/live
Liveness probe (no auth required).

GET /health/ready
Readiness probe (no auth required).

Available Models
Model	Context	Best For	Price/1K tokens
mixtral-8x7b	32K	General, coding	$0.002
llama-3-70b	8K	Complex reasoning	$0.003
phi-3-mini	4K	Quick responses	$0.0005
auto	Varies	Cost optimization	Varies
SDK Examples
Python
python
import openai

client = openai.OpenAI(
    base_url="https://<apim-name>.azure-api.net/v1",
    api_key="YOUR_API_KEY"
)

response = client.chat.completions.create(
    model="mixtral-8x7b",
    messages=[{"role": "user", "content": "Hello!"}]
)

print(response.choices[0].message.content)
JavaScript
javascript
const OpenAI = require('openai');

const client = new OpenAI({
  baseURL: 'https://<apim-name>.azure-api.net/v1',
  apiKey: 'YOUR_API_KEY'
});

const response = await client.chat.completions.create({
  model: 'mixtral-8x7b',
  messages: [{ role: 'user', content: 'Hello!' }]
});

console.log(response.choices[0].message.content);
cURL
bash
curl -X POST "https://<apim-name>.azure-api.net/v1/chat/completions" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mixtral-8x7b",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
Rate Limits
Tier	Requests/min	Tokens/min
Free	20	40,000
Starter	60	150,000
Pro	300	1,000,000
Error Handling
json
{
  "error": {
    "code": "rate_limit_exceeded",
    "message": "Rate limit exceeded",
    "retry_after": 60
  }
}
Code	Status	Action
400	Bad Request	Check request format
401	Unauthorized	Check API key
429	Rate Limited	Wait and retry
500	Server Error	Retry with backoff
503	Unavailable	Service scaling, retry
HEREDOC		
cat > docs/runbook.md << 'HEREDOC'

Operations Runbook
Monitoring
Key Metrics
API Latency: P50 < 500ms, P99 < 2s
Error Rate: < 1%
Cache Hit Rate: > 40%
VMSS Instance Count: 0-20 (auto-scaled)
Dashboards
Azure Portal â†’ Application Insights â†’ Live Metrics
Log Analytics â†’ Custom queries
Key Queries
kusto
// Error rate by endpoint
requests
| where timestamp > ago(1h)
| summarize errors = countif(success == false), total = count() by name
| extend error_rate = errors * 100.0 / total

// Latency percentiles
requests
| where timestamp > ago(1h)
| summarize p50=percentile(duration, 50), p99=percentile(duration, 99) by bin(timestamp, 5m)

// Cache hit rate
customMetrics
| where name == "cache_hit"
| summarize hits = sum(value) by bin(timestamp, 1h)
Incident Response
Severity Levels
Level	Description	Response Time
P1	Complete outage	15 min
P2	Degraded service	1 hour
P3	Minor issues	4 hours
P4	Cosmetic	Next business day
P1: Complete Outage
Verify - Check health endpoints
Communicate - Update status page
Diagnose - Check Application Insights
Mitigate - Scale VMSS, restart functions
Resolve - Fix root cause
Review - Post-incident review
Common Issues
High Latency
bash
# Check VMSS CPU
az monitor metrics list \
  --resource <vmss-resource-id> \
  --metric "Percentage CPU" \
  --interval PT1M

# Scale up if needed
az vmss scale -n <vmss-name> -g <rg-name> --new-capacity 10
Spot Instance Preemption
Automatic recovery within 30s. If persistent:

bash
# Check eviction events
az vmss list-instances -n <vmss-name> -g <rg-name> \
  --query "[].{name:name,state:provisioningState}"

# Consider increasing max price
az vmss update -n <vmss-name> -g <rg-name> \
  --set virtualMachineProfile.billingProfile.maxPrice=0.20
Function App Cold Starts
bash
# Check function health
curl https://<func-name>.azurewebsites.net/health/live

# Restart if needed
az functionapp restart -n <func-name> -g <rg-name>
Maintenance
Weekly Tasks
 Review cost reports
 Check for security updates
 Verify backup integrity
 Review error logs
Monthly Tasks
 Rotate API keys
 Update dependencies
 Capacity planning review
 Security audit
Key Rotation
bash
# Generate new API key
NEW_KEY=$(openssl rand -hex 32)

# Update Key Vault
az keyvault secret set \
  --vault-name <kv-name> \
  --name inference-api-key \
  --value "$NEW_KEY"

# Notify clients (grace period: 7 days)
Scaling Guidelines
Metric	Threshold	Action
CPU > 70%	5 min	Scale out +2
CPU < 20%	10 min	Scale in -1
Queue depth > 100	2 min	Scale out +4
Latency P99 > 5s	5 min	Scale out +2
Manual Scaling
bash
# Scale to specific count
az vmss scale -n <vmss-name> -g <rg-name> --new-capacity 10

# Update autoscale limits
az monitor autoscale update \
  --name <vmss-name>-autoscale \
  --resource-group <rg-name> \
  --max-count 30
Disaster Recovery
RTO/RPO
RTO: 1 hour
RPO: 15 minutes (cache data may be lost)
Recovery Steps
Verify secondary region resources
Update DNS/Traffic Manager
Scale secondary region VMSS
Verify health checks
Notify stakeholders
Backup Verification
bash
# Verify Cosmos DB backup
az cosmosdb show \
  --name <cosmos-name> \
  --resource-group <rg-name> \
  --query "backupPolicy"

# List recent backups
az cosmosdb restorable-database-accounts list \
  --location eastus
HEREDOC

cat > docs/architecture.md << 'HEREDOC'

Architecture Overview
System Diagram
text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CLIENTS                                     â”‚
â”‚                    (SDKs, cURL, Applications)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ HTTPS
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        API MANAGEMENT                                    â”‚
â”‚                      (Consumption Tier)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Rate      â”‚  â”‚   Auth      â”‚  â”‚  Request    â”‚  â”‚   Caching   â”‚    â”‚
â”‚  â”‚  Limiting   â”‚  â”‚ Validation  â”‚  â”‚  Routing    â”‚  â”‚  (Policy)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                       â”‚                       â”‚
          â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HEALTH API     â”‚    â”‚  INFERENCE API  â”‚    â”‚   MODELS API    â”‚
â”‚  (Anonymous)    â”‚    â”‚  (Function App) â”‚    â”‚  (Function App) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                       â”‚
                    â–¼                       â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   COSMOS DB     â”‚    â”‚   KEY VAULT     â”‚
          â”‚   (Cache)       â”‚    â”‚   (Secrets)     â”‚
          â”‚   Serverless    â”‚    â”‚                 â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          INTERNAL NETWORK                                â”‚
â”‚                           (VNet 10.0.0.0/16)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    LOAD BALANCER (Internal)                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                  â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                         VMSS (Spot GPU)                            â”‚  â”‚
â”‚  â”‚                    Standard_NC4as_T4_v3                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚  â”‚ Instance â”‚  â”‚ Instance â”‚  â”‚ Instance â”‚  â”‚ Instance â”‚  ...     â”‚  â”‚
â”‚  â”‚  â”‚ Docker   â”‚  â”‚ Docker   â”‚  â”‚ Docker   â”‚  â”‚ Docker   â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ llama.cppâ”‚  â”‚ llama.cppâ”‚  â”‚ llama.cppâ”‚  â”‚ llama.cppâ”‚          â”‚  â”‚
â”‚  â”‚  â”‚ :8080    â”‚  â”‚ :8080    â”‚  â”‚ :8080    â”‚  â”‚ :8080    â”‚          â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â”‚                                                                    â”‚  â”‚
â”‚  â”‚  Auto-scale: 0-20 instances based on CPU/Queue                    â”‚  â”‚
â”‚  â”‚  Spot pricing: ~$0.15/hour (80% discount)                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           MONITORING                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Log Analytics   â”‚  â”‚ App Insights    â”‚  â”‚ Azure Monitor   â”‚         â”‚
â”‚  â”‚ (Logs)          â”‚  â”‚ (APM)           â”‚  â”‚ (Alerts)        â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Component Details
API Management (Consumption)
Purpose: API gateway, rate limiting, authentication
Cost: ~$3.50 per million calls
Features: OpenAPI import, developer portal, analytics
Function App (Consumption)
Purpose: Request orchestration, model routing, caching
Runtime: Python 3.11
Cost: ~$0.20 per million executions
Features: Auto-scaling, managed identity, Key Vault integration
Cosmos DB (Serverless)
Purpose: Response caching, session state
Cost: ~$0.25 per million RUs
TTL: 1 hour for cached responses
Expected hit rate: 40%+
VMSS (Spot GPU)
Purpose: AI model inference
SKU: Standard_NC4as_T4_v3 (NVIDIA T4)
Cost: ~
0.15
/
h
o
u
r
s
p
o
t
(
v
s
0.15/hourspot(vs0.75 on-demand)
Container: llama.cpp with CUDA
Scale: 0-20 instances
Key Vault
Purpose: Secrets management
Stored: API keys, connection strings, certificates
Access: RBAC via managed identities
Data Flow
Client sends request to APIM
APIM validates auth, applies rate limits
Request forwarded to Function App
Function checks Cosmos DB cache
Cache miss â†’ route to VMSS
VMSS returns response
Function caches response
Response returned to client
Cost Model
Component	Idle	Active (100K req/day)
APIM	$0	~$11/month
Functions	$0	~$6/month
Cosmos DB	$0	~$15/month
VMSS (5 avg)	$0	~$540/month
Monitoring	~$5	~$20/month
Total	~$5	~$592/month
Security
All traffic over HTTPS
Managed identities (no stored credentials)
Key Vault for secrets
NSG restricts VMSS access
APIM handles authentication
HEREDOC
=============================================================================
10. SCRIPTS
=============================================================================
cat > scripts/setup-github-secrets.sh << 'HEREDOC'
#!/usr/bin/env bash
set -euo pipefail

Setup GitHub repository secrets for CI/CD
REPO="${1:-}"

if [[ -z "
R
E
P
O
"
]
]
;
t
h
e
n
e
c
h
o
"
U
s
a
g
e
:
REPO"]];thenecho"Usage:0 <owner/repo>"
exit 1
fi

echo "Setting up GitHub secrets for ${REPO}"

Check prerequisites
command -v gh &>/dev/null || { echo "GitHub CLI required"; exit 1; }
command -v az &>/dev/null || { echo "Azure CLI required"; exit 1; }

Get Azure credentials
SUBSCRIPTION_ID=
(
a
z
a
c
c
o
u
n
t
s
h
o
w
âˆ’
âˆ’
q
u
e
r
y
i
d
âˆ’
o
t
s
v
)
T
E
N
A
N
T
I
D
=
(azaccountshowâˆ’âˆ’queryidâˆ’otsv)TENANT 
I
â€‹
 D=(az account show --query tenantId -o tsv)

echo "Creating service principal..."
SP_OUTPUT=
(
a
z
a
d
s
p
c
r
e
a
t
e
âˆ’
f
o
r
âˆ’
r
b
a
c
 
âˆ’
âˆ’
n
a
m
e
"
g
i
t
h
u
b
âˆ’
a
c
t
i
o
n
s
âˆ’
(azadspcreateâˆ’forâˆ’rbac âˆ’âˆ’name"githubâˆ’actionsâˆ’{REPO////-}"
--role contributor
--scopes "/subscriptions/${SUBSCRIPTION_ID}"
--sdk-auth)

CLIENT_ID=
(
e
c
h
o
"
(echo"SP_OUTPUT" | jq -r '.clientId')
CLIENT_SECRET=
(
e
c
h
o
"
(echo"SP_OUTPUT" | jq -r '.clientSecret')

echo "Setting GitHub secrets..."

gh secret set AZURE_CREDENTIALS --repo "
R
E
P
O
"
âˆ’
âˆ’
b
o
d
y
"
REPO"âˆ’âˆ’body"SP_OUTPUT"
gh secret set ARM_CLIENT_ID --repo "
R
E
P
O
"
âˆ’
âˆ’
b
o
d
y
"
REPO"âˆ’âˆ’body"CLIENT_ID"
gh secret set ARM_CLIENT_SECRET --repo "
R
E
P
O
"
âˆ’
âˆ’
b
o
d
y
"
REPO"âˆ’âˆ’body"CLIENT_SECRET"
gh secret set ARM_SUBSCRIPTION_ID --repo "
R
E
P
O
"
âˆ’
âˆ’
b
o
d
y
"
REPO"âˆ’âˆ’body"SUBSCRIPTION_ID"
gh secret set ARM_TENANT_ID --repo "
R
E
P
O
"
âˆ’
âˆ’
b
o
d
y
"
REPO"âˆ’âˆ’body"TENANT_ID"

echo "âœ… GitHub secrets configured"
echo ""
echo "Next steps:"
echo "1. Deploy infrastructure to get Function App name"
echo "2. Set FUNCTION_APP_NAME variable in GitHub"
echo "3. Download Function App publish profile"
echo "4. Set AZURE_FUNCTIONAPP_PUBLISH_PROFILE secret"
HEREDOC
chmod +x scripts/setup-github-secrets.sh

cat > scripts/rotate-secrets.sh << 'HEREDOC'
#!/usr/bin/env bash
set -euo pipefail

Rotate secrets in Key Vault
KEY_VAULT_NAME="${1:-}"

if [[ -z "
K
E
Y
V
A
U
L
T
N
A
M
E
"
]
]
;
t
h
e
n
e
c
h
o
"
U
s
a
g
e
:
KEY 
V
â€‹
 AULT 
N
â€‹
 AME"]];thenecho"Usage:0 "
exit 1
fi

echo "Rotating secrets in ${KEY_VAULT_NAME}..."

Generate new API key
NEW_API_KEY=
(
o
p
e
n
s
s
l
r
a
n
d
âˆ’
h
e
x
32
)
a
z
k
e
y
v
a
u
l
t
s
e
c
r
e
t
s
e
t
 
âˆ’
âˆ’
v
a
u
l
t
âˆ’
n
a
m
e
"
(opensslrandâˆ’hex32)azkeyvaultsecretset âˆ’âˆ’vaultâˆ’name"KEY_VAULT_NAME"
--name "inference-api-key"
--value "
N
E
W
A
P
I
K
E
Y
"
 
âˆ’
âˆ’
t
a
g
s
r
o
t
a
t
e
d
=
"
NEW 
A
â€‹
 PI 
K
â€‹
 EY" âˆ’âˆ’tagsrotated="(date -u +%Y-%m-%dT%H:%M:%SZ)"

Generate new internal key
NEW_INTERNAL_KEY=
(
o
p
e
n
s
s
l
r
a
n
d
âˆ’
h
e
x
32
)
a
z
k
e
y
v
a
u
l
t
s
e
c
r
e
t
s
e
t
 
âˆ’
âˆ’
v
a
u
l
t
âˆ’
n
a
m
e
"
(opensslrandâˆ’hex32)azkeyvaultsecretset âˆ’âˆ’vaultâˆ’name"KEY_VAULT_NAME"
--name "internal-service-key"
--value "
N
E
W
I
N
T
E
R
N
A
L
K
E
Y
"
 
âˆ’
âˆ’
t
a
g
s
r
o
t
a
t
e
d
=
"
NEW 
I
â€‹
 NTERNAL 
K
â€‹
 EY" âˆ’âˆ’tagsrotated="(date -u +%Y-%m-%dT%H:%M:%SZ)"

echo "âœ… Secrets rotated"
echo ""
echo "âš ï¸ Remember to:"
echo "1. Update any external clients with new API key"
echo "2. Allow grace period before disabling old keys"
HEREDOC
chmod +x scripts/rotate-secrets.sh

cat > scripts/cleanup.sh << 'HEREDOC'
#!/usr/bin/env bash
set -euo pipefail

Cleanup all resources
RESOURCE_GROUP="${1:-}"

if [[ -z "
R
E
S
O
U
R
C
E
G
R
O
U
P
"
]
]
;
t
h
e
n
e
c
h
o
"
U
s
a
g
e
:
RESOURCE 
G
â€‹
 ROUP"]];thenecho"Usage:0 "
exit 1
fi

echo "âš ï¸ This will DELETE all resources in ${RESOURCE_GROUP}"
read -p "Are you sure? (yes/no): " confirm

if [[ "$confirm" != "yes" ]]; then
echo "Aborted"
exit 0
fi

echo "Deleting resource group..."
az group delete --name "$RESOURCE_GROUP" --yes --no-wait

echo "âœ… Deletion initiated (async)"
echo "Monitor: az group show -n $RESOURCE_GROUP"
HEREDOC
chmod +x scripts/cleanup.sh

=============================================================================
11. FINAL SETUP
=============================================================================
Create Terraform environments directory
mkdir -p terraform/environments
cat > terraform/environments/dev.tfvars << 'HEREDOC'
project_name = "ai-inference"
environment = "dev"
location = "eastus"
vmss_min_instances = 0
vmss_max_instances = 5
admin_email = "dev@example.com"
HEREDOC

cat > terraform/environments/prod.tfvars << 'HEREDOC'
project_name = "ai-inference"
environment = "prod"
location = "eastus"
vmss_min_instances = 0
vmss_max_instances = 20
admin_email = "admin@example.com"
HEREDOC

Make scripts executable
chmod +x deploy.sh

Initialize git
git init
git add .
git commit -m "Initial commit: AI Inference Arbitrage Platform"

=============================================================================
COMPLETION MESSAGE
=============================================================================
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ… PROJECT CREATED SUCCESSFULLY: 
P
R
O
J
E
C
T
N
A
M
E
"
e
c
h
o
"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"
e
c
h
o
"
"
e
c
h
o
"
ðŸ“
P
r
o
j
e
c
t
S
t
r
u
c
t
u
r
e
:
"
e
c
h
o
"
"
f
i
n
d
.
âˆ’
t
y
p
e
f
âˆ’
n
a
m
e
"
âˆ—
.
t
f
"
âˆ’
o
âˆ’
n
a
m
e
"
âˆ—
.
b
i
c
e
p
"
âˆ’
o
âˆ’
n
a
m
e
"
âˆ—
.
p
y
"
âˆ’
o
âˆ’
n
a
m
e
"
âˆ—
.
s
h
"
âˆ’
o
âˆ’
n
a
m
e
"
âˆ—
.
y
m
l
"
âˆ’
o
âˆ’
n
a
m
e
"
âˆ—
.
m
d
"
âˆ’
o
âˆ’
n
a
m
e
"
âˆ—
.
j
s
o
n
"
2
>
/
d
e
v
/
n
u
l
l
âˆ£
h
e
a
d
âˆ’
50
âˆ£
s
o
r
t
e
c
h
o
"
"
e
c
h
o
"
ðŸ“‹
Q
u
i
c
k
S
t
a
r
t
:
"
e
c
h
o
"
"
e
c
h
o
"
O
p
t
i
o
n
1
âˆ’
B
a
s
h
:
"
e
c
h
o
"
c
d
PROJECT 
N
â€‹
 AME"echo"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"echo""echo"ðŸ“ProjectStructure:"echo""find.âˆ’typefâˆ’name"âˆ—.tf"âˆ’oâˆ’name"âˆ—.bicep"âˆ’oâˆ’name"âˆ—.py"âˆ’oâˆ’name"âˆ—.sh"âˆ’oâˆ’name"âˆ—.yml"âˆ’oâˆ’name"âˆ—.md"âˆ’oâˆ’name"âˆ—.json"2>/dev/nullâˆ£headâˆ’50âˆ£sortecho""echo"ðŸ“‹QuickStart:"echo""echo"Option1âˆ’Bash:"echo"cd{PROJECT_NAME}"
echo " ./deploy.sh"
echo ""
echo " Option 2 - Terraform:"
echo " cd 
P
R
O
J
E
C
T
N
A
M
E
/
t
e
r
r
a
f
o
r
m
"
e
c
h
o
"
t
e
r
r
a
f
o
r
m
i
n
i
t
"
e
c
h
o
"
t
e
r
r
a
f
o
r
m
p
l
a
n
"
e
c
h
o
"
t
e
r
r
a
f
o
r
m
a
p
p
l
y
"
e
c
h
o
"
"
e
c
h
o
"
O
p
t
i
o
n
3
âˆ’
B
i
c
e
p
:
"
e
c
h
o
"
c
d
PROJECT 
N
â€‹
 AME/terraform"echo"terraforminit"echo"terraformplan"echo"terraformapply"echo""echo"Option3âˆ’Bicep:"echo"cd{PROJECT_NAME}"
echo " az deployment sub create --location eastus --template-file bicep/main.bicep"
echo ""
echo "ðŸ“š Documentation:"
echo " docs/deployment-guide.md"
echo " docs/api-usage.md"
echo " docs/architecture.md"
echo " docs/runbook.md"
echo ""
echo "ðŸ” Features:"
echo " âœ“ Health check endpoints (/health/live, /health/ready)"
echo " âœ“ Azure Key Vault secrets management"
echo " âœ“ Terraform infrastructure"
echo " âœ“ Bicep infrastructure"
echo " âœ“ GitHub Actions CI/CD"
echo " âœ“ Comprehensive tests"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

text

To use this script:

```bash
# Save the entire script above to a file
cat > create-project.sh << 'EOF'
# [paste the entire script here]
EOF

# Make it executable
chmod +x create-project.sh

# Run it (optionally specify a project name)
./create-project.sh my-ai-platform

# Or use the default name
./create-project.sh